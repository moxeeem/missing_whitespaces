# Восстановление пробелов в тексте

Модель для быстрого и точного восстановления пропущенных пробелов, основанная на SOTA-подходе.

## Подход

Решение базируется на статье **[Fast Whitespace Correction with Encoder-Only Transformers](https://aclanthology.org/2023.acl-demo.37/)** (ACL 2023).

Задача решается как **позиционная классификация**: для каждого символа в тексте модель параллельно определяет одно из трёх действий:

  * **Оставить** символ как есть.
  * **Удалить** символ (если это лишний пробел).
  * **Вставить пробел** перед символом.

Такой дизайн обеспечивает высокую скорость работы и малый размер модели.

-----

## Результаты

Метрики получены на тестовом наборе данных с использованием чекпоинта `checkpoint_epoch_3.pt`.

Этот результат и был отправлен на тестирующую платформу Степика.

| Метрика | Train | Validation | Test (Submission) |
| :--- | :--- | :--- | :--- |
| Кол-во примеров | 395943 | 43994 | 1005 |
| **F1-score** | СКОРО | СКОРО | **93.614%** |
| **Время (сек)** | - | - | **10.0** |

-----

## Источники данных

Для обучения использовалась комбинация двух датасетов для охвата как коротких, так и длинных текстов:

1.  **[Avito ML Cup 2025](https://ods.ai/competitions/avitotechmlchallenge2025_2)**: Поля `title` и `description` из объявлений.
2.  **[WMT News Crawl](https://data.statmt.org/news-crawl/ru/)**: Короткие предложения из новостных статей на русском языке.

-----

## Структура репозитория

```
.
├── README.md                      # Этот файл
├── requirements.txt               # Зависимости проекта
├── missing_whitespaces.ipynb      # Jupyter-ноутбук (обучение и инференс)
├── dataset_1937770_3.txt          # Тестовый датасет для сабмита
├── submission.csv                 # Итоговый файл с результатами
└── restored_texts.txt             # Примеры восстановленных строк
```

-----

## Быстрый старт

### 1\. Настройка окружения (Python 3.10+)

```bash
# Создание и активация виртуального окружения
python -m venv .venv

# Windows
.venv\Scripts\activate

# Linux / macOS
source .venv/bin/activate

# Установка зависимостей
pip install -r requirements.txt
```

### 2\. Запуск

#### Вариант А: Полный цикл (Обучение + Инференс)

1.  Откройте ноутбук `missing_whitespaces.ipynb`.
2.  Нажмите **"Run All"** (Выполнить все). Ноутбук последовательно выполнит все шаги: от загрузки данных до обучения и сохранения результата.

#### Вариант Б: Только Инференс (с готовой моделью)

1.  Скачайте [архив с чекпоинтом](https://drive.google.com/drive/folders/1HrPQOcORhsCyqjTVmX6IY-46V89-KqpC?usp=sharing).
2.  Распакуйте его так, чтобы файл модели находился по пути:
    > `experiments/eo_byte_finetune/checkpoint_epoch_3.pt`
3.  Откройте `missing_whitespaces.ipynb` и запустите только последний раздел **"Inference"**. Он не зависит от ячеек с обучением.

-----

## Среда для экспериментов

  * **GPU**: NVIDIA RTX A4000 (16 ГБ VRAM)
  * **RAM**: 47 ГБ

------

## Контакты

* **Максим Иванов**  
  Email: moxeeeem@gmail.com
  Telegram: [@fwznn_ql1d_8](https://t.me/fwznn_ql1d_8)
