{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d9a8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch torchvision torchaudio numpy pandas matplotlib scikit-learn tqdm requests pyyaml pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60152377",
   "metadata": {},
   "source": [
    "# Восстановление пропущенных пробелов в тексте\n",
    "\n",
    "Тестовое задание от Авито\n",
    "\n",
    "Иванов Максим (moxeeeem@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8dd1256",
   "metadata": {},
   "source": [
    "На Авито пользователи часто вводят тексты в поиске, описаниях или заголовках с опечатками, \n",
    "пропущенными пробелами или слитным написанием слов (например: книгавхорошемсостоянии).\n",
    "Такие тексты усложняют понимание, снижают качество поиска и мешают автоматическому анализу \n",
    "(например, извлечению сущностей). \n",
    "\n",
    "Да, можно просто использовать дорогую LLM модель, но как будто такая задача может решаться \n",
    "гораздо более дешевым и быстрым способом. Мы ищем именно такое решение - точное, быстрое и легковесное.\n",
    "\n",
    "Задача — разработать модель или алгоритм, который принимает на вход текст без пробелов и \n",
    "возвращает восстановленный текст с правильными пробелами и позициями, где они были пропущены. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294484eb",
   "metadata": {},
   "source": [
    "**Метрика**\n",
    "\n",
    "Качество оценивается по F1-score для позиций пропущенных пробелов.\n",
    "\n",
    "Для каждой строки мы сравниваем множество позиций, где вы поставили пробелы, с истинным множеством.\n",
    "\n",
    "Формула: \n",
    "\n",
    "$$\\text{F1} = 2 * \\frac{\\text{precision} * \\text{recall}}{\\text{precision} + \\text{recall}}$$\n",
    "\n",
    "где:\n",
    "\n",
    "$$\\text{precision} = \\frac{|\\text{предсказанные} \\cap \\text{истинные}|}{|\\text{предсказанные}|}$$\n",
    "$$\\text{recall} = \\frac{|\\text{предсказанные} \\cap \\text{истинные}|}{|\\text{истинные}|}$$\n",
    "\n",
    "Окончательная метрика — средний F1 по всем текстам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c3bde",
   "metadata": {},
   "source": [
    "**Таблица метрик**\n",
    "\n",
    "|                   | Train      | Validation    | Test (Submission)    |\n",
    "|-------------------|------------|---------------|----------------------|\n",
    "| Number of samples | 395943     | 43994         | 1005                 |\n",
    "| F1-score          | -          | -             | 93.614%              |\n",
    "| Time (sec)        | -          | -             | 10.0                 |\n",
    "\n",
    "\n",
    "**Описание подхода**\n",
    "\n",
    "Представленное решение базируется на статье - [Fast Whitespace Correction with Encoder-Only Transformers](https://aclanthology.org/2023.acl-demo.37/).\n",
    "Это SOTA подход для задачи восстановления пробелов, опубликованный в 2023 году.\n",
    "\n",
    "Его главное преимущество и особенность - быстрота и лёгкость модели (вариант с Encoder-Only Transformer), что позволяет использовать её в продакшене с ограниченными ресурсами. Это именно наш случай, когда нужно быстро и эффективно исправлять тексты пользователей.\n",
    "\n",
    "Основная идея модели заключается в том, чтобы рассматривать исправление пробелов не как генерацию нового текста, а как задачу классификации. Модель для каждого символа в тексте параллельно решает, что с ним сделать: оставить, удалить или вставить перед ним пробел, что делает ее чрезвычайно быстрой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c13dd00",
   "metadata": {},
   "source": [
    "**Экспериментальная среда**\n",
    "\n",
    "Все эксперименты проводились на машине со следующими характеристиками:\n",
    "- Оперативная память: 47 GB\n",
    "- Графический процессор: NVIDIA RTX A4000 (16 GB видеопамяти)\n",
    "- Время прогона всего ноутбука от начала и до конца: 00 минут"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49b7004",
   "metadata": {},
   "source": [
    "## Настройка окружения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e2e3e",
   "metadata": {},
   "source": [
    "Начнём с импортов и простых настроек логов - все дальнейшие разделы будем пользоваться этими зависимостями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "245f7bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import ast\n",
    "import gc\n",
    "import gzip\n",
    "import io\n",
    "import json\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import unicodedata\n",
    "import zipfile\n",
    "from dataclasses import dataclass\n",
    "from contextlib import contextmanager\n",
    "from pathlib import Path\n",
    "from collections.abc import Iterable, Iterator, Sequence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import yaml\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "643fad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "logger = logging.getLogger('whitespace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f74e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings_to_silence = [\n",
    "    'enable_nested_tensor is True, but self.use_nested_tensor is False',\n",
    "]\n",
    "for warning_message in warnings_to_silence:\n",
    "    logging.captureWarnings(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43183b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "IPYNB_TIME_START = time.time()\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "DATA_DIR = PROJECT_ROOT / 'avito_parts'\n",
    "NEWS_CACHE = PROJECT_ROOT / 'ru_news_short.txt'\n",
    "RANDOM_STATE = 42\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "AMP = DEVICE == 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9129e889",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee1b2018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:33:47,447 INFO: Работаем на устройстве: cuda\n"
     ]
    }
   ],
   "source": [
    "logger.info('Работаем на устройстве: %s', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bac7a00",
   "metadata": {},
   "source": [
    "Подавляем предупреждение PyTorch, которое возникло из-за копирования логики из статьи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4c31e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "for warning_message in warnings_to_silence:\n",
    "    warnings.filterwarnings('ignore', message=warning_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4c4686",
   "metadata": {},
   "source": [
    "Чтобы результаты можно было воспроизвести, фиксируем случайные сиды"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1553b38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:33:47,459 INFO: Фиксируем генераторы случайных чисел значением 42\n"
     ]
    }
   ],
   "source": [
    "def set_global_seed(seed: int) -> None:\n",
    "    '''\n",
    "    Фиксирует генераторы случайных чисел Python, NumPy и PyTorch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Значение, используемое для инициализации псевдослучайных генераторов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Функция не возвращает значение и выполняет настройку генераторов на месте.\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "\n",
    "set_global_seed(RANDOM_STATE)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "logger.info('Фиксируем генераторы случайных чисел значением %d', RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821d9901",
   "metadata": {},
   "source": [
    "Собираем краткие сведения о железе и версиях ключевых библиотек, чтобы понимать контекст полученных результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb46b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:33:47,546 INFO: python: 3.10.12\n",
      "2025-09-24 17:33:47,547 INFO: pytorch: 2.8.0+cu128\n",
      "2025-09-24 17:33:47,547 INFO: platform: Linux-5.15.0-100-generic-x86_64-with-glibc2.35\n",
      "2025-09-24 17:33:47,547 INFO: cpu: x86_64\n",
      "2025-09-24 17:33:47,548 INFO: cpu_cores: 16\n",
      "2025-09-24 17:33:47,548 INFO: gpu: NVIDIA RTX A4000\n",
      "2025-09-24 17:33:47,548 INFO: gpu_memory_gb: 15.73\n",
      "2025-09-24 17:33:47,548 INFO: ram_gb: 46.97\n",
      "2025-09-24 17:33:47,547 INFO: pytorch: 2.8.0+cu128\n",
      "2025-09-24 17:33:47,547 INFO: platform: Linux-5.15.0-100-generic-x86_64-with-glibc2.35\n",
      "2025-09-24 17:33:47,547 INFO: cpu: x86_64\n",
      "2025-09-24 17:33:47,548 INFO: cpu_cores: 16\n",
      "2025-09-24 17:33:47,548 INFO: gpu: NVIDIA RTX A4000\n",
      "2025-09-24 17:33:47,548 INFO: gpu_memory_gb: 15.73\n",
      "2025-09-24 17:33:47,548 INFO: ram_gb: 46.97\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import platform\n",
    "\n",
    "import pkg_resources\n",
    "\n",
    "\n",
    "def collect_system_info() -> dict[str, Any]:\n",
    "    '''\n",
    "    Собирает информацию о доступном оборудовании и версиях интерпретатора.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, Any]\n",
    "        Словарь с ключевыми характеристиками CPU, GPU, ОЗУ и версией Python.\n",
    "    '''\n",
    "    info: dict[str, Any] = {}\n",
    "    info['python'] = sys.version.split()[0]\n",
    "    info['pytorch'] = torch.__version__\n",
    "    info['platform'] = platform.platform()\n",
    "    info['cpu'] = platform.processor() or platform.machine()\n",
    "    info['cpu_cores'] = multiprocessing.cpu_count()\n",
    "    if torch.cuda.is_available():\n",
    "        device_props = torch.cuda.get_device_properties(0)\n",
    "        info['gpu'] = device_props.name\n",
    "        info['gpu_memory_gb'] = round(device_props.total_memory / 1024 ** 3, 2)\n",
    "    else:\n",
    "        info['gpu'] = 'No GPU'\n",
    "        info['gpu_memory_gb'] = 0.0\n",
    "    try:\n",
    "        import psutil  # type: ignore\n",
    "\n",
    "        mem = psutil.virtual_memory()\n",
    "        info['ram_gb'] = round(mem.total / 1024 ** 3, 2)\n",
    "    except ImportError:\n",
    "        info['ram_gb'] = None\n",
    "    return info\n",
    "\n",
    "\n",
    "def print_system_info(info: dict[str, Any]) -> None:\n",
    "    '''\n",
    "    Печатает системную информацию в человекочитаемом виде.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    info : dict[str, Any]\n",
    "        Словарь, полученный в результате вызова collect_system_info.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        Функция выводит данные в стандартный поток и ничего не возвращает.\n",
    "    '''\n",
    "    for key, value in info.items():\n",
    "        logger.info('%s: %s', key, value)\n",
    "\n",
    "\n",
    "def list_package_versions(packages: Sequence[str]) -> dict[str, str]:\n",
    "    '''\n",
    "    Возвращает версии указанных пакетов, установленных в окружении.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    packages : Sequence[str]\n",
    "        Список имен пакетов, для которых требуется узнать версии.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, str]\n",
    "        Словарь вида {\"package\": \"version\"}.\n",
    "    '''\n",
    "    versions: dict[str, str] = {}\n",
    "    for package in packages:\n",
    "        try:\n",
    "            versions[package] = pkg_resources.get_distribution(package).version\n",
    "        except pkg_resources.DistributionNotFound:\n",
    "            versions[package] = 'not installed'\n",
    "    return versions\n",
    "\n",
    "\n",
    "system_info = collect_system_info()\n",
    "print_system_info(system_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "436fe62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch==2.8.0\n",
      "torchvision==0.23.0\n",
      "torchaudio==2.8.0\n",
      "numpy==2.2.6\n",
      "pandas==2.3.2\n",
      "matplotlib==3.10.6\n",
      "scikit-learn==1.7.2\n",
      "tqdm==4.67.1\n",
      "requests==2.32.5\n",
      "pyyaml==6.0.2\n",
      "pyarrow==21.0.0\n"
     ]
    }
   ],
   "source": [
    "packages = ['torch', 'torchvision', 'torchaudio', 'numpy', 'pandas', \n",
    "            'matplotlib', 'scikit-learn', 'tqdm', 'requests', 'pyyaml', \n",
    "            'pyarrow']\n",
    "\n",
    "versions = list_package_versions(packages)\n",
    "for name, ver in versions.items():\n",
    "    print(f'{name}=={ver}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c54b851",
   "metadata": {},
   "source": [
    "## Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cb392c",
   "metadata": {},
   "source": [
    "Мы объединяем два источника:\n",
    "1. Части датасета с соревнования [Avito ML Cup 2025 - Поиск дублей](https://ods.ai/competitions/avitotechmlchallenge2025_2) с полями `base_title`, `cand_title`, `base_description`, `cand_description`.\n",
    "\n",
    "2. Новости [WMT News Crawl corpus](data.statmt.org/news-crawl/ru/), из которых извлекаем короткие предложения для адекватной работы модели на небольших текстах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afdf2df1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:33:47,566 INFO: Каталог данных: /home/avito_parts\n"
     ]
    }
   ],
   "source": [
    "PART_URLS: dict[str, str] = {\n",
    "    'train_part_0001': 'https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0001.snappy.parquet',\n",
    "    'train_part_0002': 'https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0002.snappy.parquet',\n",
    "    'train_part_0003': 'https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0003.snappy.parquet',\n",
    "    'train_part_0004': 'https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/train_part_0004.snappy.parquet',\n",
    "    'test_part_0001': 'https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/test_part_0001.snappy.parquet',\n",
    "    'test_part_0002': 'https://storage.yandexcloud.net/ds-ods/files/data/docs/competitions/Avitotechcomp2025/data_competition_2/test_part_0002.snappy.parquet',\n",
    "}\n",
    "\n",
    "TEXT_COLUMNS = ['base_title', 'cand_title', 'base_description', 'cand_description']\n",
    "NEWS_URLS: Sequence[str] = (\n",
    "    'https://data.statmt.org/news-crawl/ru/news.2017.ru.shuffled.deduped.gz',\n",
    "    'https://data.statmt.org/news-crawl/ru/news.2018.ru.shuffled.deduped.gz',\n",
    "    'https://data.statmt.org/news-crawl/ru/news.2019.ru.shuffled.deduped.gz',\n",
    "    'https://data.statmt.org/news-crawl/ru/news.2020.ru.shuffled.deduped.gz',\n",
    ")\n",
    "\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "logger.info('Каталог данных: %s', DATA_DIR.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944cb4c2",
   "metadata": {},
   "source": [
    "### Функции скачивания и кэширования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22605811",
   "metadata": {},
   "source": [
    "Реализуем обертки над `requests`, чтобы бережно работать с сетью, кэшировать результаты и показывать прогресс"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e452056f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file(url: str, dst: Path, *, desc: str | None = None, chunk_size: int = 2 ** 20) -> Path:\n",
    "    '''\n",
    "    Скачивает файл по HTTP с отображением прогресса и кэшированием на диске.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    url : str\n",
    "        Адрес, откуда загружается файл.\n",
    "    dst : Path\n",
    "        Локальный путь, по которому сохраняется результат.\n",
    "    desc : str, optional\n",
    "        Подпись прогресс-бара. По умолчанию формируется из имени файла.\n",
    "    chunk_size : int, optional\n",
    "        Размер куска данных в байтах. По умолчанию 1 МБ.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path\n",
    "        Путь к загруженному файлу.\n",
    "    '''\n",
    "    if dst.exists() and dst.stat().st_size > 0:\n",
    "        logger.info('Файл %s уже скачан, пропускаем загрузку', dst.name)\n",
    "        return dst\n",
    "    response = requests.get(url, stream=True, timeout=120)\n",
    "    response.raise_for_status()\n",
    "    total = int(response.headers.get('content-length', 0)) or None\n",
    "    progress_label = desc or f'GET {dst.name}'\n",
    "    with open(dst, 'wb') as fout, tqdm(total=total, unit='B', unit_scale=True, desc=progress_label) as bar:\n",
    "        for chunk in response.iter_content(chunk_size=chunk_size):\n",
    "            if not chunk:\n",
    "                continue\n",
    "            fout.write(chunk)\n",
    "            bar.update(len(chunk))\n",
    "    return dst\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def timer(task: str) -> Iterator[None]:\n",
    "    '''\n",
    "    Контекстный менеджер для измерения времени выполнения блока кода.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    task : str\n",
    "        Человекочитаемое описание задачи.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Iterator[None]\n",
    "        Итератор, который фиксирует время старта и окончания контекста.\n",
    "    '''\n",
    "    start = time.time()\n",
    "    logger.info('[%s] старт', task)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        duration = time.time() - start\n",
    "        logger.info('[%s] завершено за %.2f c (%.2f мин)', task, duration, duration / 60)\n",
    "\n",
    "\n",
    "def ensure_partitions(part_names: Sequence[str]) -> list[Path]:\n",
    "    '''\n",
    "    Гарантирует наличие выбранных parquet-фрагментов соревнования Avito на диске.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    part_names : Sequence[str]\n",
    "        Перечень ключей из словаря PART_URLS.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[Path]\n",
    "        Список локальных путей к скачанным файлам.\n",
    "    '''\n",
    "    paths: list[Path] = []\n",
    "    for part_name in part_names:\n",
    "        if part_name not in PART_URLS:\n",
    "            raise KeyError(f'Неизвестная часть датасета: {part_name}')\n",
    "        url = PART_URLS[part_name]\n",
    "        local_path = DATA_DIR / Path(url).name\n",
    "        download_file(url, local_path)\n",
    "        paths.append(local_path)\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda0eee3",
   "metadata": {},
   "source": [
    "### Нормализация и нарезка новостного корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b027f667",
   "metadata": {},
   "source": [
    "Чтобы усилить модель на коротких фразах, извлекаем из новостей предложения ограниченной длины. Нормализуем пробелы, удаляем скрытые символы и дополнительно нарезаем длинные предложения на словосочетания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1a030b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ZBREAKS = re.compile(r'[\\u2028\\u2029\\u0085]')\n",
    "_ZEROWIDTH = re.compile(r'[\\u200b\\u200c\\u200d\\ufeff]')\n",
    "_SPACES = re.compile(r'\\s+')\n",
    "_SENTENCE_SPLIT = re.compile(r'(?<=[.!?])\\s+')\n",
    "_CLAUSE_SPLIT = re.compile(r'[,:;\\-\\—\\(\\)\\[\\]{}]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6c9c985",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    '''\n",
    "    Приводит строку к аккуратному виду: убирает спецсимволы и повторяющиеся пробелы.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Входная строка с произвольными пробельными символами.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Очищенный текст с одинарными пробелами и обрезанными краями.\n",
    "    '''\n",
    "    cleaned = _ZBREAKS.sub(' ', text)\n",
    "    cleaned = _ZEROWIDTH.sub('', cleaned)\n",
    "    cleaned = cleaned.replace('\\xa0', ' ')\n",
    "    cleaned = _SPACES.sub(' ', cleaned)\n",
    "    return cleaned.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e9917be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentences(line: str) -> list[str]:\n",
    "    '''\n",
    "    Разбивает строку на предложения, сохраняя только непустые части.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : str\n",
    "        Строка из корпуса новостей.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        Список кандидатов на обработку.\n",
    "    '''\n",
    "    return [chunk.strip() for chunk in _SENTENCE_SPLIT.split(line) if chunk.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34969728",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_candidate_fragments(sentence: str) -> list[str]:\n",
    "    '''\n",
    "    Формирует набор коротких фрагментов из предложения.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    sentence : str\n",
    "        Исходное предложение.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        Набор очищенных фрагментов, подходящих по длине.\n",
    "    '''\n",
    "    sentence_norm = normalize_text(sentence)\n",
    "    if not sentence_norm:\n",
    "        return []\n",
    "    words = sentence_norm.split()\n",
    "    fragments: list[str] = []\n",
    "    if 2 <= len(words) <= 14 and 12 <= len(sentence_norm) <= 160:\n",
    "        fragments.append(sentence_norm if sentence_norm.endswith('.') else sentence_norm + '.')\n",
    "        return fragments\n",
    "    for clause in _CLAUSE_SPLIT.split(sentence_norm):\n",
    "        clause = clause.strip()\n",
    "        if not clause:\n",
    "            continue\n",
    "        if clause[-1:] not in '.!?':\n",
    "            clause += '.'\n",
    "        if 2 <= len(clause.split()) <= 10 and 12 <= len(clause) <= 140:\n",
    "            fragments.append(clause)\n",
    "    if not fragments and len(words) >= 5:\n",
    "        middle_start = max(0, (len(words) - 6) // 2)\n",
    "        middle = ' '.join(words[middle_start:middle_start + 6])\n",
    "        if middle[-1:] not in '.!?':\n",
    "            middle += '.'\n",
    "        fragments.append(middle)\n",
    "    return list(dict.fromkeys(fragments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c6ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_news_fragments(urls: Sequence[str], *, limit: int = 4_000_000, cache_path: Path = NEWS_CACHE) -> list[str]:\n",
    "    '''\n",
    "    Загружает и кэширует набор коротких предложений из новостного корпуса.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    urls : Sequence[str]\n",
    "        Список URL с gzip-файлами новостей.\n",
    "    limit : int, optional\n",
    "        Максимальное количество фрагментов, сохраняемых в кэш. По умолчанию 4 млн.\n",
    "    cache_path : Path, optional\n",
    "        Локальный файл для хранения предобработанного списка.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[str]\n",
    "        Коллекция коротких нормализованных предложений.\n",
    "    '''\n",
    "    if cache_path.exists():\n",
    "        logger.info('Используем кэш новостных фрагментов %s', cache_path)\n",
    "        return cache_path.read_text(encoding='utf-8').splitlines()\n",
    "    collected: list[str] = []\n",
    "    with cache_path.open('w', encoding='utf-8') as fout:\n",
    "        for url in urls:\n",
    "            with timer(f'news {Path(url).name}'):\n",
    "                response = requests.get(url, stream=True, timeout=180)\n",
    "                response.raise_for_status()\n",
    "                gzip_file = gzip.GzipFile(fileobj=response.raw)\n",
    "                buffer = io.BufferedReader(gzip_file)\n",
    "                for raw_line in buffer:\n",
    "                    if len(collected) >= limit:\n",
    "                        break\n",
    "                    try:\n",
    "                        line = raw_line.decode('utf-8')\n",
    "                    except UnicodeDecodeError:\n",
    "                        line = raw_line.decode('utf-8', errors='replace')\n",
    "                    for sentence in split_sentences(line):\n",
    "                        for fragment in extract_candidate_fragments(sentence):\n",
    "                            fout.write(fragment + '\\n')\n",
    "                            collected.append(fragment)\n",
    "                            if len(collected) >= limit:\n",
    "                                break\n",
    "                        if len(collected) >= limit:\n",
    "                            break\n",
    "                    if len(collected) >= limit:\n",
    "                        break\n",
    "            if len(collected) >= limit:\n",
    "                break\n",
    "    logger.info('Получено %d фрагментов из новостей', len(collected))\n",
    "    return collected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72168094",
   "metadata": {},
   "source": [
    "### Обработка частей соревнования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2ec84d",
   "metadata": {},
   "source": [
    "Читаем parquet-файлы, выбираем текстовые поля, нормализуем пробелы и объединяем с новостными примерами.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f56cdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_NORMALIZE_PATTERN = re.compile(r'\\s+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6bfc3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_avito_texts(part_paths: Sequence[Path]) -> pd.Series:\n",
    "    '''\n",
    "    Загружает и нормализует текстовые поля из parquet-файлов соревнования Avito.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    part_paths : Sequence[Path]\n",
    "        Пути к локальным parquet-файлам.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Серия с уникальными строками, очищенными от лишних пробелов.\n",
    "    '''\n",
    "    texts: list[pd.Series] = []\n",
    "    for path in part_paths:\n",
    "        df_part = pd.read_parquet(path)\n",
    "        for column in TEXT_COLUMNS:\n",
    "            if column not in df_part.columns:\n",
    "                continue\n",
    "            series = (\n",
    "                df_part[column]\n",
    "                .dropna()\n",
    "                .astype(str)\n",
    "                .map(normalize_text)\n",
    "            )\n",
    "            series = series[series != '']\n",
    "            if not series.empty:\n",
    "                texts.append(series)\n",
    "    if not texts:\n",
    "        return pd.Series(dtype=str)\n",
    "    merged = pd.concat(texts, ignore_index=True).drop_duplicates()\n",
    "    logger.info('Из частей соревнования получено %d уникальных строк', len(merged))\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d98b54e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:33:47,617 INFO: Файл train_part_0001.snappy.parquet уже скачан, пропускаем загрузку\n",
      "2025-09-24 17:33:47,617 INFO: Файл train_part_0002.snappy.parquet уже скачан, пропускаем загрузку\n",
      "2025-09-24 17:33:47,617 INFO: Файл train_part_0002.snappy.parquet уже скачан, пропускаем загрузку\n",
      "2025-09-24 17:35:27,901 INFO: Из частей соревнования получено 1898607 уникальных строк\n",
      "2025-09-24 17:35:28,112 INFO: Используем кэш новостных фрагментов /home/ru_news_short.txt\n",
      "2025-09-24 17:35:33,702 INFO: Итоговый корпус содержит 4692666 предложений\n"
     ]
    }
   ],
   "source": [
    "SELECTED_PARTS = ['train_part_0001', 'train_part_0002']\n",
    "avito_part_paths = ensure_partitions(SELECTED_PARTS)\n",
    "avito_texts = load_avito_texts(avito_part_paths)\n",
    "news_fragments = collect_news_fragments(NEWS_URLS, limit=3_000_000)\n",
    "\n",
    "corpus_series = pd.concat([avito_texts, pd.Series(news_fragments)], ignore_index=True).drop_duplicates()\n",
    "corpus_series = corpus_series[corpus_series.str.len() > 0].reset_index(drop=True)\n",
    "logger.info('Итоговый корпус содержит %d предложений', len(corpus_series))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b8876f",
   "metadata": {},
   "source": [
    "Почти ПЯТЬ миллионов уникальных непустых текстов, но не надо пугаться - останутся далеко не все - позже отберем сбалансированную выборку"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae03133",
   "metadata": {},
   "source": [
    "### Разведочный анализ корпуса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a99710e",
   "metadata": {},
   "source": [
    "Посмотрим на распределения длин предложений и количества пробелов, чтобы настроить стратифицированную выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cf09bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:35:41,596 INFO: Краткие статистики: {'count': 4692666, 'min_len': 1, 'median_len': 49.0, 'mean_len': 232.88468985433866, 'p95_len': 1460.0, 'max_len': 9203, 'mean_spaces': 31.955347770329276, 'corr_len_spaces': 0.9938226649680821}\n"
     ]
    }
   ],
   "source": [
    "corpus_df = pd.DataFrame({'text': corpus_series})\n",
    "corpus_df['length'] = corpus_df['text'].str.len()\n",
    "corpus_df['spaces'] = corpus_df['text'].str.count(' ')\n",
    "\n",
    "summary_stats = {\n",
    "    'count': int(corpus_df.shape[0]),\n",
    "    'min_len': int(corpus_df['length'].min()),\n",
    "    'median_len': float(corpus_df['length'].median()),\n",
    "    'mean_len': float(corpus_df['length'].mean()),\n",
    "    'p95_len': float(corpus_df['length'].quantile(0.95)),\n",
    "    'max_len': int(corpus_df['length'].max()),\n",
    "    'mean_spaces': float(corpus_df['spaces'].mean()),\n",
    "    'corr_len_spaces': float(corpus_df['length'].corr(corpus_df['spaces'])),\n",
    "}\n",
    "logger.info('Краткие статистики: %s', summary_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "859571ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "corpus_df['length'].plot.kde(lw=2, color='tab:blue')\n",
    "plt.title('Плотность распределения длины предложений')\n",
    "plt.xlabel('Длина, символы')\n",
    "plt.xlim(0, corpus_df['length'].quantile(0.99))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63abe7e7",
   "metadata": {},
   "source": [
    "Видим сильный перекос распределения. Средняя длина сильно больше медианы - основной холм распределения находится в районе десятков–сотен символов, но есть длинный хвост вплоть до 9203.\n",
    "\n",
    "Пробелы почти линейно растут с длиной (corr~0.993). Значит, количество вставок и длина - почти одно и то же. Но, это ок: чем длиннее текст, тем больше потенциальных позиций для пробелов.\n",
    "\n",
    "min_len=1 - есть шум/очень короткие строки, будем резать. Если этого не делать, то модель запомнит большинство коротких текстов и провалится на длинных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50187a64",
   "metadata": {},
   "source": [
    "KDE-кривая подтверждает наличие слишком длинного хвоста: высокая плотность у коротких/средних текстов, затем длинный низкий плато-хвост"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a486f29",
   "metadata": {},
   "source": [
    "### Подготовка таргетов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ef91f9",
   "metadata": {},
   "source": [
    "Следуем формуле статьи: исходный текст $x$ превращаем в пару $(\\tilde{x}, P)$, где $\\tilde{x}$ - строка без пробелов, а множество позиций $P$ описывает, куда необходимо вставить пробелы.\n",
    "\n",
    "Конкретнее: преобразуем каждую строку в пару `(no_space, positions)`, где `no_space` - текст без пробелов, а `positions` - индексы, куда эти пробелы нужно вернуть. Дополнительно сохраняем полезные утилиты для прямого и обратного преобразования.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47cbbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(frozen=True)\n",
    "class Example:\n",
    "    '''\n",
    "    Описывает компактную форму строки без пробелов и индексы пробелов\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    no_space : str\n",
    "        Текст без пробелов\n",
    "    positions : list[int]\n",
    "        Индексы пробелов в компактной строке\n",
    "    '''\n",
    "    no_space: str\n",
    "    positions: list[int]\n",
    "\n",
    "\n",
    "def make_example(text: str) -> Example:\n",
    "    '''\n",
    "    Преобразует текст в компактное представление и индексы пробелов\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Исходная строка с пробелами\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Example\n",
    "        Объект с текстом без пробелов и списком индексов\n",
    "    '''\n",
    "    cleaned = TEXT_NORMALIZE_PATTERN.sub(' ', str(text)).strip()\n",
    "    if not cleaned:\n",
    "        return Example('', [])\n",
    "    compact_chars: list[str] = []\n",
    "    positions: list[int] = []\n",
    "    compact_index = 0\n",
    "    was_space = True\n",
    "    for char in cleaned:\n",
    "        if char == ' ':\n",
    "            if not was_space:\n",
    "                positions.append(compact_index)\n",
    "            was_space = True\n",
    "        else:\n",
    "            compact_chars.append(char)\n",
    "            compact_index += 1\n",
    "            was_space = False\n",
    "    return Example(''.join(compact_chars), positions)\n",
    "\n",
    "\n",
    "def apply_positions(no_space: str, positions: Sequence[int]) -> str:\n",
    "    '''\n",
    "    Восстанавливает пробелы в компактной строке по заданным индексам\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    no_space : str\n",
    "        Строка без пробелов\n",
    "    positions : Sequence[int]\n",
    "        Коллекция индексов пробелов\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Строка с восстановленными пробелами\n",
    "    '''\n",
    "    insert_positions = {int(pos) for pos in positions}\n",
    "    buffer: list[str] = []\n",
    "    for idx, char in enumerate(no_space):\n",
    "        if idx in insert_positions:\n",
    "            buffer.append(' ')\n",
    "        buffer.append(char)\n",
    "    if len(no_space) in insert_positions:\n",
    "        buffer.append(' ')\n",
    "    restored = ''.join(buffer)\n",
    "    return TEXT_NORMALIZE_PATTERN.sub(' ', restored).strip()\n",
    "\n",
    "\n",
    "def check_roundtrip(text: str) -> bool:\n",
    "    '''\n",
    "    Проверяет взаимное преобразование строки в компактный формат и обратно\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Исходная строка\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True, если восстановленный текст совпадает с исходным после нормализации\n",
    "    '''\n",
    "    example = make_example(text)\n",
    "    restored = apply_positions(example.no_space, example.positions)\n",
    "    return normalize_text(text) == restored\n",
    "\n",
    "\n",
    "assert check_roundtrip('Трехколесный самокат с ручным тормозом')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13633096",
   "metadata": {},
   "source": [
    "Добавляем к каждой строке строку без пробелов и список позиций. Заодно фильтруем пустые и слишком короткие примеры.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "653c4b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:39:58,855 INFO: После фильтрации осталось 3804111 строк\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spaces",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "no_space",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "true_positions",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "compact_len",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "6eed8491-7e70-407b-aa2f-a0ba1fa02a33",
       "rows": [
        [
         "0",
         "Зимние ботинки ecco",
         "19",
         "2",
         "Зимниеботинкиecco",
         "[6, 13]",
         "17"
        ],
        [
         "1",
         "Куpткa зимняя и ветpовкa",
         "24",
         "3",
         "Куpткaзимняяиветpовкa",
         "[6, 12, 13]",
         "21"
        ],
        [
         "2",
         "Свaдебное плaтье cо шлейфом 46 48",
         "33",
         "5",
         "Свaдебноеплaтьеcошлейфом4648",
         "[9, 15, 17, 24, 26]",
         "28"
        ],
        [
         "3",
         "Зимний конвеpт в коляcку",
         "24",
         "3",
         "Зимнийконвеpтвколяcку",
         "[6, 13, 14]",
         "21"
        ],
        [
         "4",
         "Эндоcкопичеcкие тpaнcнaзaльные доcтупы",
         "38",
         "2",
         "Эндоcкопичеcкиетpaнcнaзaльныедоcтупы",
         "[15, 29]",
         "36"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>spaces</th>\n",
       "      <th>no_space</th>\n",
       "      <th>true_positions</th>\n",
       "      <th>compact_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Зимние ботинки ecco</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>Зимниеботинкиecco</td>\n",
       "      <td>[6, 13]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Куpткa зимняя и ветpовкa</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Куpткaзимняяиветpовкa</td>\n",
       "      <td>[6, 12, 13]</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Свaдебное плaтье cо шлейфом 46 48</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>Свaдебноеплaтьеcошлейфом4648</td>\n",
       "      <td>[9, 15, 17, 24, 26]</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Зимний конвеpт в коляcку</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>Зимнийконвеpтвколяcку</td>\n",
       "      <td>[6, 13, 14]</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Эндоcкопичеcкие тpaнcнaзaльные доcтупы</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "      <td>Эндоcкопичеcкиетpaнcнaзaльныедоcтупы</td>\n",
       "      <td>[15, 29]</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     text  length  spaces  \\\n",
       "0                     Зимние ботинки ecco      19       2   \n",
       "1                Куpткa зимняя и ветpовкa      24       3   \n",
       "2       Свaдебное плaтье cо шлейфом 46 48      33       5   \n",
       "3                Зимний конвеpт в коляcку      24       3   \n",
       "4  Эндоcкопичеcкие тpaнcнaзaльные доcтупы      38       2   \n",
       "\n",
       "                               no_space       true_positions  compact_len  \n",
       "0                     Зимниеботинкиecco              [6, 13]           17  \n",
       "1                 Куpткaзимняяиветpовкa          [6, 12, 13]           21  \n",
       "2          Свaдебноеплaтьеcошлейфом4648  [9, 15, 17, 24, 26]           28  \n",
       "3                 Зимнийконвеpтвколяcку          [6, 13, 14]           21  \n",
       "4  Эндоcкопичеcкиетpaнcнaзaльныедоcтупы             [15, 29]           36  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIN_LEN = 3\n",
    "MAX_LEN = 100\n",
    "\n",
    "examples: list[Example] = [make_example(text) for text in corpus_df['text']]\n",
    "corpus_df['no_space'] = [example.no_space for example in examples]\n",
    "corpus_df['true_positions'] = [example.positions for example in examples]\n",
    "\n",
    "corpus_df['compact_len'] = corpus_df['no_space'].str.len()\n",
    "corpus_df = corpus_df[(corpus_df['compact_len'] >= MIN_LEN) & (corpus_df['compact_len'] <= MAX_LEN)]\n",
    "corpus_df = corpus_df.reset_index(drop=True)\n",
    "logger.info('После фильтрации осталось %d строк', len(corpus_df))\n",
    "\n",
    "corpus_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684f04a",
   "metadata": {},
   "source": [
    "#### Балансировка и стратификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4b35e2",
   "metadata": {},
   "source": [
    "Чтобы модель видела широкий спектр длин и количеств пробелов, используем двойную стратификацию: по длине строки и по числу целевых пробелов. Это уменьшает дисперсию метрики.\n",
    "\n",
    "Тексты с разной длиной и плотностью пробелов по-разному сложны для модели. Мы хотим, чтобы в обучении и валидации были схожие доли простых/сложных случаев.\n",
    "\n",
    "Мы дискретизируем оба признака по квантилям (по X корзин на каждый)\n",
    "\n",
    "Корзина - интервал значений одного признака. Мы делим длину текста на X корзин по квантилям (qcut) и число пробелов тоже на X корзин. Получим интервалы вида (106.0, 357.0] и (15.0, 51.0] - это как раз границы двух корзин по длине и по пробелам.\n",
    "\n",
    "Страты - пересечения корзин по двум признакам (какие тексты одновременно попали в такой-то интервал длины и такой-то интервал числа пробелов), будем отбирать из каждой страты одинаковое число примеров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2551f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_LEN_BINS = 8\n",
    "N_SPACE_BINS = 8\n",
    "TARGET_TOTAL = 1_000_000\n",
    "CAP_PER_STRATUM = 10_000\n",
    "MIN_PER_STRATUM = 50\n",
    "VAL_SHARE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0dd2678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_strata(df: pd.DataFrame, *, len_bins: int, space_bins: int) -> pd.Series:\n",
    "    '''\n",
    "    Вычисляет страты по квантилям длины строки и количества пробелов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Датафрейм с колонками `compact_len` и `true_positions`.\n",
    "    len_bins : int\n",
    "        Количество квантильных корзин по длине строки.\n",
    "    space_bins : int\n",
    "        Количество квантильных корзин по числу пробелов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.Series\n",
    "        Серия с ярлыками страт.\n",
    "    '''\n",
    "    length_labels = pd.qcut(df['compact_len'], q=len_bins, duplicates='drop')\n",
    "    space_counts = df['true_positions'].map(len)\n",
    "    space_labels = pd.qcut(space_counts, q=space_bins, duplicates='drop')\n",
    "    return length_labels.astype(str) + '|' + space_labels.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15116c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:02,081 INFO: Будем забирать до 10000 примеров из каждой страты\n"
     ]
    }
   ],
   "source": [
    "corpus_df['_strata'] = assign_strata(corpus_df, len_bins=N_LEN_BINS, space_bins=N_SPACE_BINS)\n",
    "stratum_counts = corpus_df['_strata'].value_counts()\n",
    "valid_strata = stratum_counts[stratum_counts >= MIN_PER_STRATUM].index\n",
    "corpus_df = corpus_df[corpus_df['_strata'].isin(valid_strata)].reset_index(drop=True)\n",
    "\n",
    "per_stratum_target = min(CAP_PER_STRATUM, max(MIN_PER_STRATUM, TARGET_TOTAL // max(len(valid_strata), 1)))\n",
    "logger.info('Будем забирать до %d примеров из каждой страты', per_stratum_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4703111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:03,580 INFO: Сбалансированный корпус: 439937 примеров и 57 страт\n"
     ]
    }
   ],
   "source": [
    "balanced_parts: list[pd.DataFrame] = []\n",
    "for stratum, group in corpus_df.groupby('_strata'):\n",
    "    take = min(len(group), per_stratum_target)\n",
    "    balanced_parts.append(group.sample(n=take, random_state=RANDOM_STATE))\n",
    "\n",
    "balanced_df = pd.concat(balanced_parts, ignore_index=True).sample(frac=1.0, random_state=RANDOM_STATE).reset_index(drop=True)\n",
    "logger.info('Сбалансированный корпус: %d примеров и %d страт', len(balanced_df), balanced_df['_strata'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb7d241",
   "metadata": {},
   "source": [
    "Мы сделали:\n",
    "- фильтр длины\n",
    "- удалили редкие страты\n",
    "- ограничили потолок на страту и целевой объём\n",
    "\n",
    "Итоговая выборка после всех трех шагов стала гораздо меньше: это компромисс между представлением всех типов строк и ресурсами обучения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568eeaa4",
   "metadata": {},
   "source": [
    "#### Разделение на обучающую и валидационную выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df148cee",
   "metadata": {},
   "source": [
    "Используем `StratifiedShuffleSplit`, чтобы распределение страт сохранилось в обеих частях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "715f2101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:04,159 INFO: Train: 395943 примеров, Val: 43994 примеров\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "spaces",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "no_space",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "true_positions",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "compact_len",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "_strata",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "80171319-2586-473b-aea6-e8d092b01e9e",
       "rows": [
        [
         "0",
         "Бaнкнотa кндp 1000 вон 2006 год № 777645. UNC",
         "45",
         "8",
         "Бaнкнотaкндp1000вон2006год№777645.UNC",
         "[8, 12, 16, 19, 23, 26, 27, 34]",
         "37",
         "(31.0, 37.0]|(7.0, 9.0]"
        ],
        [
         "1",
         "\"Сегодня правительство (Каталонии.",
         "34",
         "2",
         "\"Сегодняправительство(Каталонии.",
         "[8, 21]",
         "32",
         "(31.0, 37.0]|(-0.001, 2.0]"
        ],
        [
         "2",
         "Однако, это был совет, а не запрет.",
         "35",
         "6",
         "Однако,этобылсовет,анезапрет.",
         "[7, 10, 13, 19, 20, 22]",
         "29",
         "(25.0, 31.0]|(5.0, 6.0]"
        ]
       ],
       "shape": {
        "columns": 7,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>length</th>\n",
       "      <th>spaces</th>\n",
       "      <th>no_space</th>\n",
       "      <th>true_positions</th>\n",
       "      <th>compact_len</th>\n",
       "      <th>_strata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Бaнкнотa кндp 1000 вон 2006 год № 777645. UNC</td>\n",
       "      <td>45</td>\n",
       "      <td>8</td>\n",
       "      <td>Бaнкнотaкндp1000вон2006год№777645.UNC</td>\n",
       "      <td>[8, 12, 16, 19, 23, 26, 27, 34]</td>\n",
       "      <td>37</td>\n",
       "      <td>(31.0, 37.0]|(7.0, 9.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Сегодня правительство (Каталонии.</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>\"Сегодняправительство(Каталонии.</td>\n",
       "      <td>[8, 21]</td>\n",
       "      <td>32</td>\n",
       "      <td>(31.0, 37.0]|(-0.001, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Однако, это был совет, а не запрет.</td>\n",
       "      <td>35</td>\n",
       "      <td>6</td>\n",
       "      <td>Однако,этобылсовет,анезапрет.</td>\n",
       "      <td>[7, 10, 13, 19, 20, 22]</td>\n",
       "      <td>29</td>\n",
       "      <td>(25.0, 31.0]|(5.0, 6.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text  length  spaces  \\\n",
       "0  Бaнкнотa кндp 1000 вон 2006 год № 777645. UNC      45       8   \n",
       "1             \"Сегодня правительство (Каталонии.      34       2   \n",
       "2            Однако, это был совет, а не запрет.      35       6   \n",
       "\n",
       "                                no_space                   true_positions  \\\n",
       "0  Бaнкнотaкндp1000вон2006год№777645.UNC  [8, 12, 16, 19, 23, 26, 27, 34]   \n",
       "1       \"Сегодняправительство(Каталонии.                          [8, 21]   \n",
       "2          Однако,этобылсовет,анезапрет.          [7, 10, 13, 19, 20, 22]   \n",
       "\n",
       "   compact_len                     _strata  \n",
       "0           37     (31.0, 37.0]|(7.0, 9.0]  \n",
       "1           32  (31.0, 37.0]|(-0.001, 2.0]  \n",
       "2           29     (25.0, 31.0]|(5.0, 6.0]  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=VAL_SHARE, random_state=RANDOM_STATE)\n",
    "train_idx, val_idx = next(splitter.split(balanced_df, balanced_df['_strata']))\n",
    "train_df = balanced_df.iloc[train_idx].reset_index(drop=True)\n",
    "val_df = balanced_df.iloc[val_idx].reset_index(drop=True)\n",
    "logger.info('Train: %d примеров, Val: %d примеров', len(train_df), len(val_df))\n",
    "\n",
    "train_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b7debc",
   "metadata": {},
   "source": [
    "При стратифицированном сплите мы ожидаем, что распределение страт похоже в обоих множествах. Это делает метрику честной: val задаёт те же пропорции простых/сложных примеров, что и train, а не смещённый срез.\n",
    "\n",
    "Рассчитаем доли страт и сравним их. Значения в строке для одной и той же страты должны быть близкими (разница в пределах небольшого шума).\n",
    "\n",
    "Если train или val сильно просел (например, 0 в валидации, но 4–5% в трейне) - это знак, что у страты мало примеров и её стоило либо не включать, либо поднять TARGET_TOTAL/CAP_PER_STRAT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff0003d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "_strata",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "train",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "val",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "1876ef57-8702-44cd-aa25-d7da4e202d24",
       "rows": [
        [
         "(19.0, 25.0]|(-0.001, 2.0]",
         "0.02273054454807889",
         "0.02273037232349866"
        ],
        [
         "(19.0, 25.0]|(2.0, 3.0]",
         "0.02273054454807889",
         "0.02273037232349866"
        ],
        [
         "(19.0, 25.0]|(3.0, 4.0]",
         "0.02273054454807889",
         "0.02273037232349866"
        ],
        [
         "(19.0, 25.0]|(4.0, 5.0]",
         "0.02273054454807889",
         "0.02273037232349866"
        ],
        [
         "(19.0, 25.0]|(5.0, 6.0]",
         "0.01633568468188603",
         "0.016343137700595537"
        ],
        [
         "(19.0, 25.0]|(6.0, 7.0]",
         "0.002596333310602789",
         "0.0025912624448788473"
        ],
        [
         "(19.0, 25.0]|(7.0, 9.0]",
         "0.0004394571945961919",
         "0.0004318770741464745"
        ],
        [
         "(2.999, 19.0]|(-0.001, 2.0]",
         "0.02273054454807889",
         "0.02273037232349866"
        ],
        [
         "(2.999, 19.0]|(2.0, 3.0]",
         "0.02273054454807889",
         "0.02273037232349866"
        ],
        [
         "(2.999, 19.0]|(3.0, 4.0]",
         "0.02273054454807889",
         "0.02273037232349866"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 10
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_strata</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(19.0, 25.0]|(-0.001, 2.0]</th>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.022730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(19.0, 25.0]|(2.0, 3.0]</th>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.022730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(19.0, 25.0]|(3.0, 4.0]</th>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.022730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(19.0, 25.0]|(4.0, 5.0]</th>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.022730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(19.0, 25.0]|(5.0, 6.0]</th>\n",
       "      <td>0.016336</td>\n",
       "      <td>0.016343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(19.0, 25.0]|(6.0, 7.0]</th>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.002591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(19.0, 25.0]|(7.0, 9.0]</th>\n",
       "      <td>0.000439</td>\n",
       "      <td>0.000432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2.999, 19.0]|(-0.001, 2.0]</th>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.022730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2.999, 19.0]|(2.0, 3.0]</th>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.022730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(2.999, 19.0]|(3.0, 4.0]</th>\n",
       "      <td>0.022731</td>\n",
       "      <td>0.022730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                train       val\n",
       "_strata                                        \n",
       "(19.0, 25.0]|(-0.001, 2.0]   0.022731  0.022730\n",
       "(19.0, 25.0]|(2.0, 3.0]      0.022731  0.022730\n",
       "(19.0, 25.0]|(3.0, 4.0]      0.022731  0.022730\n",
       "(19.0, 25.0]|(4.0, 5.0]      0.022731  0.022730\n",
       "(19.0, 25.0]|(5.0, 6.0]      0.016336  0.016343\n",
       "(19.0, 25.0]|(6.0, 7.0]      0.002596  0.002591\n",
       "(19.0, 25.0]|(7.0, 9.0]      0.000439  0.000432\n",
       "(2.999, 19.0]|(-0.001, 2.0]  0.022731  0.022730\n",
       "(2.999, 19.0]|(2.0, 3.0]     0.022731  0.022730\n",
       "(2.999, 19.0]|(3.0, 4.0]     0.022731  0.022730"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    train_df['_strata'].value_counts(normalize=True).rename('train'),\n",
    "    val_df['_strata'].value_counts(normalize=True).rename('val')\n",
    "], axis=1).fillna(0).sort_index().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fea300",
   "metadata": {},
   "source": [
    "Видим, что доли страт валидации и тренировки очень близки построчно - значит, стратификация сработала корректно: train и val статистически сопоставимы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee55c2e",
   "metadata": {},
   "source": [
    "## Аугментация: искусственные ошибки пробелов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88ebdb3",
   "metadata": {},
   "source": [
    "Для повышения устойчивости модели добавляем синтетические ошибки: случайно удаляем часть пробелов и вставляем лишние. Параметры подобраны экспериментально так, чтобы имитировать реальные опечатки пользователей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc4621b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_DELETE_SPACE = 0.35\n",
    "P_INSERT_SPACE = 0.12\n",
    "MAX_INSERTED_SPACES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "724056b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:04,251 INFO: Пример аугментации: Авто м ати ческая кофемаши н асовстроенной кофемолкой\n"
     ]
    }
   ],
   "source": [
    "def corrupt_whitespaces(text: str, *, rng: random.Random | None = None) -> str:\n",
    "    '''\n",
    "    Искажает пробелы в тексте: удаляет часть и вставляет лишние.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Эталонная строка с корректными пробелами.\n",
    "    rng : random.Random, optional\n",
    "        Инициализированный генератор случайных чисел.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Строка с синтетическими ошибками пробелов.\n",
    "    '''\n",
    "    generator = rng or random\n",
    "    normalized = TEXT_NORMALIZE_PATTERN.sub(' ', text).strip()\n",
    "    if not normalized:\n",
    "        return ''\n",
    "    chars = list(normalized)\n",
    "    idx = 0\n",
    "    while idx < len(chars):\n",
    "        if chars[idx] == ' ' and generator.random() < P_DELETE_SPACE:\n",
    "            start = idx\n",
    "            while idx < len(chars) and chars[idx] == ' ':\n",
    "                idx += 1\n",
    "            del chars[start:idx]\n",
    "            idx = start\n",
    "        else:\n",
    "            idx += 1\n",
    "    insertions: list[tuple[int, int]] = []\n",
    "    for pos in range(1, len(chars)):\n",
    "        if chars[pos - 1] != ' ' and chars[pos] != ' ' and generator.random() < P_INSERT_SPACE:\n",
    "            count = 1 + generator.randint(0, MAX_INSERTED_SPACES)\n",
    "            insertions.append((pos, count))\n",
    "    shift = 0\n",
    "    for pos, count in insertions:\n",
    "        chars[pos + shift:pos + shift] = [' '] * count\n",
    "        shift += count\n",
    "    corrupted = ''.join(chars)\n",
    "    corrupted = TEXT_NORMALIZE_PATTERN.sub(' ', corrupted)\n",
    "    return corrupted.strip()\n",
    "\n",
    "\n",
    "corrupted_demo = corrupt_whitespaces('Автоматическая кофемашина со встроенной кофемолкой', rng=random.Random(RANDOM_STATE))\n",
    "logger.info('Пример аугментации: %s', corrupted_demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080f4bde",
   "metadata": {},
   "source": [
    "Для каждого исходного текста добавляем как минимум две версии: идеальную и искаженную. Это ускоряет схождение и повышает метрику F1 на валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6fc481a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:13,210 INFO: Количество обучающих примеров (с учетом аугментации): 791886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Бa нкнотa кндp1000вон 2 006 год № 777645.UN C',\n",
       "  [8, 12, 16, 19, 23, 26, 27, 34]),\n",
       " ('Бaнкнотaкндp1000вон2006год№777645.UNC', [8, 12, 16, 19, 23, 26, 27, 34]),\n",
       " ('\"Сегодня прав ительство (Кат ал онии.', [8, 21])]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples: list[tuple[str, list[int]]] = []\n",
    "random_generator = random.Random(RANDOM_STATE)\n",
    "\n",
    "for text, no_space, positions in zip(train_df['text'], train_df['no_space'], train_df['true_positions']):\n",
    "    corrupted = corrupt_whitespaces(text, rng=random_generator)\n",
    "    if corrupted:\n",
    "        train_examples.append((corrupted, positions))\n",
    "    if no_space:\n",
    "        train_examples.append((no_space, positions))\n",
    "\n",
    "logger.info('Количество обучающих примеров (с учетом аугментации): %d', len(train_examples))\n",
    "train_examples[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf5b5b2",
   "metadata": {},
   "source": [
    "#### Подготовка окон и классов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5dffb2",
   "metadata": {},
   "source": [
    "Модель предсказывает три класса на каждом токене: `Keep`, `Insert`, `Delete`. Чтобы компенсировать дисбаланс (преобладание класса `Keep`), рассчитываем частоты на случайной подвыборке и формируем веса для Focal Loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ce3b195",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEFT_CTX = 64\n",
    "RIGHT_CTX = 64\n",
    "MAX_TOKENS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "496a377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grapheme_spans(text: str) -> tuple[str, list[tuple[int, int]]]:\n",
    "    '''\n",
    "    Получает нормализованный текст и диапазоны графем для устойчивой токенизации.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Исходная строка.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, list[tuple[int, int]]]\n",
    "        Нормализованный текст и список пар (start, end) по графемам.\n",
    "    '''\n",
    "    normalized = unicodedata.normalize('NFKC', text)\n",
    "    spans: list[tuple[int, int]] = []\n",
    "    start = 0\n",
    "    for idx in range(1, len(normalized)):\n",
    "        if unicodedata.combining(normalized[idx]):\n",
    "            continue\n",
    "        spans.append((start, idx))\n",
    "        start = idx\n",
    "    spans.append((start, len(normalized)))\n",
    "    return normalized, spans\n",
    "\n",
    "\n",
    "def token_byte_lengths(norm_text: str, spans: Sequence[tuple[int, int]]) -> np.ndarray:\n",
    "    '''\n",
    "    Подсчитывает длины графем в байтах UTF-8.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm_text : str\n",
    "        Нормализованный текст.\n",
    "    spans : Sequence[tuple[int, int]]\n",
    "        Диапазоны графем.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Массив длин в байтах для каждой графемы.\n",
    "    '''\n",
    "    return np.fromiter((len(norm_text[start:end].encode('utf-8', errors='ignore')) for start, end in spans), dtype=np.int32)\n",
    "\n",
    "\n",
    "def labels_from_positions(norm_text: str, spans: Sequence[tuple[int, int]], positions: Sequence[int]) -> list[int]:\n",
    "    '''\n",
    "    Преобразует список позиций пробелов в последовательность меток классов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm_text : str\n",
    "        Нормализованный текст.\n",
    "    spans : Sequence[tuple[int, int]]\n",
    "        Диапазоны графем.\n",
    "    positions : Sequence[int]\n",
    "        Целевые индексы для вставки пробелов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[int]\n",
    "        Список меток классов: 0 — Keep, 1 — Insert, 2 — Delete.\n",
    "    '''\n",
    "    need_space_before = {int(pos) for pos in positions}\n",
    "    labels: list[int] = []\n",
    "    compact_idx = 0\n",
    "    for start, end in spans:\n",
    "        token = norm_text[start:end]\n",
    "        if token.strip() == '':\n",
    "            labels.append(2)\n",
    "            continue\n",
    "        if compact_idx in need_space_before and compact_idx > 0:\n",
    "            labels.append(1)\n",
    "            need_space_before.discard(compact_idx)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "        compact_idx += 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "def labels_to_positions(norm_text: str, spans: Sequence[tuple[int, int]], labels: Sequence[int]) -> list[int]:\n",
    "    '''\n",
    "    Переводит метки классов обратно в список индексов пробелов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm_text : str\n",
    "        Нормализованный текст.\n",
    "    spans : Sequence[tuple[int, int]]\n",
    "        Диапазоны графем.\n",
    "    labels : Sequence[int]\n",
    "        Последовательность предсказанных классов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[int]\n",
    "        Список позиций пробелов.\n",
    "    '''\n",
    "    positions: list[int] = []\n",
    "    compact_idx = 0\n",
    "    for label, (start, end) in zip(labels, spans):\n",
    "        token = norm_text[start:end]\n",
    "        if token.strip() == '':\n",
    "            continue\n",
    "        if label == 1 and compact_idx > 0:\n",
    "            prev_char = norm_text[start - 1] if start > 0 else ''\n",
    "            if prev_char != ' ':\n",
    "                positions.append(compact_idx)\n",
    "        compact_idx += 1\n",
    "    return positions\n",
    "\n",
    "\n",
    "def make_token_windows(num_tokens: int, *, max_tokens: int, left_ctx: int, right_ctx: int) -> list[tuple[int, int, int, int]]:\n",
    "    '''\n",
    "    Разбивает последовательность на окна с перекрытием и контекстом.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_tokens : int\n",
    "        Длина последовательности в графемах.\n",
    "    max_tokens : int\n",
    "        Максимальное число графем в одном окне.\n",
    "    left_ctx : int\n",
    "        Ширина левого контекста.\n",
    "    right_ctx : int\n",
    "        Ширина правого контекста.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int, int, int]]\n",
    "        Список окон в формате (start, end, core_start, core_end).\n",
    "    '''\n",
    "    if num_tokens <= max_tokens:\n",
    "        return [(0, num_tokens, 0, num_tokens)]\n",
    "    core = max_tokens - left_ctx - right_ctx\n",
    "    if core <= 0:\n",
    "        raise ValueError('Размер контекста должен быть меньше общего окна')\n",
    "    windows: list[tuple[int, int, int, int]] = []\n",
    "    start = 0\n",
    "    while start < num_tokens:\n",
    "        core_start = start\n",
    "        core_end = min(start + core, num_tokens)\n",
    "        win_start = max(0, core_start - left_ctx)\n",
    "        win_end = min(num_tokens, core_end + right_ctx)\n",
    "        core_rel_start = core_start - win_start\n",
    "        core_rel_end = core_end - win_start\n",
    "        windows.append((win_start, win_end, core_rel_start, core_rel_end))\n",
    "        start = core_end\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "799489f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_SAMPLE_SIZE = 8_000\n",
    "class_counter = np.zeros(3, dtype=np.int64)\n",
    "subset = random.sample(train_examples, min(CLASS_SAMPLE_SIZE, len(train_examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "20ea45ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:13,574 INFO: Частоты классов (K, I, D): [0.78388761 0.12775856 0.08835383]\n",
      "2025-09-24 17:40:13,575 INFO: Веса классов для FocalLoss: [0.18740823 1.14987972 1.66271205]\n",
      "2025-09-24 17:40:13,575 INFO: Веса классов для FocalLoss: [0.18740823 1.14987972 1.66271205]\n"
     ]
    }
   ],
   "source": [
    "for corrupt_text, positions in subset:\n",
    "    norm_text, spans = grapheme_spans(corrupt_text)\n",
    "    if not spans:\n",
    "        continue\n",
    "    labels = labels_from_positions(norm_text, spans, positions)\n",
    "    bincount = np.bincount(np.array(labels, dtype=np.int64), minlength=3)\n",
    "    class_counter += bincount\n",
    "\n",
    "class_frequencies = class_counter / class_counter.sum()\n",
    "class_weights = 1.0 / (class_frequencies + 1e-8)\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "CLASS_WEIGHTS = torch.tensor(class_weights, dtype=torch.float32, device=DEVICE)\n",
    "logger.info('Частоты классов (K, I, D): %s', class_frequencies)\n",
    "logger.info('Веса классов для FocalLoss: %s', class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77de795a",
   "metadata": {},
   "source": [
    "Модель работает на байтовых последовательностях. Поэтому каждую строку разбиваем на окна с контекстом, где ядро попадает в предел `MAX_TOKENS`. Это уменьшает память и позволяет обрабатывать длинные тексты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "900ea0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass(slots=True)\n",
    "class WindowSample:\n",
    "    '''\n",
    "    Представляет одно окно текста в байтовом виде с метками и масками ядра.\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    byte_values : np.ndarray\n",
    "        Последовательность байтов окна.\n",
    "    token_lengths : np.ndarray\n",
    "        Длины графем в байтах.\n",
    "    labels : np.ndarray\n",
    "        Метки классов для каждой графемы окна.\n",
    "    core_mask : np.ndarray\n",
    "        Булев маска, ограничивающая ядро окна, которое участвует в функции потерь.\n",
    "    '''\n",
    "    byte_values: np.ndarray\n",
    "    token_lengths: np.ndarray\n",
    "    labels: np.ndarray\n",
    "    core_mask: np.ndarray\n",
    "\n",
    "\n",
    "def prepare_windows(examples: Sequence[tuple[str, Sequence[int]]], *,\n",
    "                    max_tokens: int = MAX_TOKENS, left_ctx: int = LEFT_CTX,\n",
    "                    right_ctx: int = RIGHT_CTX, desc: str = 'prepare windows') -> list[WindowSample]:\n",
    "    '''\n",
    "    Преобразует список примеров в список окон для обучения.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    examples : Sequence[tuple[str, Sequence[int]]]\n",
    "        Список пар (текст, позиции пробелов).\n",
    "    max_tokens : int, optional\n",
    "        Максимальная длина окна в графемах.\n",
    "    left_ctx : int, optional\n",
    "        Ширина левого контекста для окна.\n",
    "    right_ctx : int, optional\n",
    "        Ширина правого контекста для окна.\n",
    "    desc : str, optional\n",
    "        Подпись прогресс-бара.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[WindowSample]\n",
    "        Список окон в байтовом представлении.\n",
    "    '''\n",
    "    windows: list[WindowSample] = []\n",
    "    for text, positions in tqdm(examples, desc=desc):\n",
    "        if not text:\n",
    "            continue\n",
    "        norm_text, spans = grapheme_spans(text)\n",
    "        if not spans:\n",
    "            continue\n",
    "        labels = np.asarray(labels_from_positions(norm_text, spans, positions), dtype=np.int64)\n",
    "        if labels.size == 0:\n",
    "            continue\n",
    "        token_lens = token_byte_lengths(norm_text, spans)\n",
    "        encoded = norm_text.encode('utf-8', errors='ignore')\n",
    "        offsets = np.concatenate(([0], np.cumsum(token_lens, dtype=np.int64)))\n",
    "        for win_start, win_end, core_rel_start, core_rel_end in make_token_windows(len(spans), max_tokens=max_tokens, left_ctx=left_ctx, right_ctx=right_ctx):\n",
    "            if win_end <= win_start:\n",
    "                continue\n",
    "            byte_start = int(offsets[win_start])\n",
    "            byte_end = int(offsets[win_end])\n",
    "            chunk_bytes = np.frombuffer(encoded[byte_start:byte_end], dtype=np.uint8).copy()\n",
    "            chunk_lengths = token_lens[win_start:win_end].astype(np.int32, copy=True)\n",
    "            chunk_labels = labels[win_start:win_end].astype(np.int64, copy=True)\n",
    "            if chunk_labels.size == 0:\n",
    "                continue\n",
    "            core_mask = np.zeros(chunk_labels.size, dtype=np.bool_)\n",
    "            core_mask[core_rel_start:core_rel_end] = True\n",
    "            windows.append(WindowSample(\n",
    "                byte_values=chunk_bytes,\n",
    "                token_lengths=chunk_lengths,\n",
    "                labels=chunk_labels,\n",
    "                core_mask=core_mask,\n",
    "            ))\n",
    "    return windows\n",
    "\n",
    "\n",
    "class WindowDataset(Dataset[WindowSample]):\n",
    "    '''\n",
    "    PyTorch-совместимый датасет окон.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : Sequence[WindowSample]\n",
    "        Готовые окна для обучения.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, samples: Sequence[WindowSample]):\n",
    "        self._samples = list(samples)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self._samples)\n",
    "\n",
    "    def __getitem__(self, index: int) -> WindowSample:\n",
    "        return self._samples[index]\n",
    "\n",
    "\n",
    "def collate_window_batch(batch: Sequence[WindowSample]) -> dict[str, object]:\n",
    "    '''\n",
    "    Формирует батч для модели из списка окон.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch : Sequence[WindowSample]\n",
    "        Коллекция объектов WindowSample.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str, object]\n",
    "        Словарь с батчем байтов, длин, меток и масок.\n",
    "    '''\n",
    "    batch_size = len(batch)\n",
    "    max_tokens = max(sample.labels.shape[0] for sample in batch)\n",
    "    labels = torch.zeros((batch_size, max_tokens), dtype=torch.long)\n",
    "    core_mask = torch.zeros((batch_size, max_tokens), dtype=torch.bool)\n",
    "    byte_tensors: list[torch.Tensor] = []\n",
    "    length_tensors: list[torch.Tensor] = []\n",
    "    for idx, sample in enumerate(batch):\n",
    "        token_count = sample.labels.shape[0]\n",
    "        labels[idx, :token_count] = torch.from_numpy(sample.labels)\n",
    "        core_mask[idx, :token_count] = torch.from_numpy(sample.core_mask)\n",
    "        byte_tensors.append(torch.from_numpy(sample.byte_values.astype(np.int64, copy=False)))\n",
    "        length_tensors.append(torch.from_numpy(sample.token_lengths.astype(np.int64, copy=False)))\n",
    "    return {\n",
    "        'byte_values': byte_tensors,\n",
    "        'token_lengths': length_tensors,\n",
    "        'labels': labels,\n",
    "        'core_mask': core_mask,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8bbedc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:13,594 INFO: [prepare training windows] старт\n",
      "windows train: 100%|██████████| 791886/791886 [00:34<00:00, 22666.40it/s]\n",
      "2025-09-24 17:40:48,533 INFO: [prepare training windows] завершено за 34.94 c (0.58 мин)\n",
      "2025-09-24 17:40:48,539 INFO: Всего окон для обучения: 791886\n"
     ]
    }
   ],
   "source": [
    "with timer('prepare training windows'):\n",
    "    train_windows = prepare_windows(\n",
    "        train_examples,\n",
    "        max_tokens=MAX_TOKENS,\n",
    "        left_ctx=LEFT_CTX,\n",
    "        right_ctx=RIGHT_CTX,\n",
    "        desc='windows train',\n",
    "    )\n",
    "\n",
    "train_dataset = WindowDataset(train_windows)\n",
    "logger.info('Всего окон для обучения: %d', len(train_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7c17cd",
   "metadata": {},
   "source": [
    "## Encoder-Only Transformer для восстановления пробелов в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a978962c",
   "metadata": {},
   "source": [
    "Ключевая идея этой encoder-only модели - в переосмыслении задачи исправления пробелов. Вместо того чтобы генерировать исправленный текст последовательно (как это делают модели encoder-decoder), она решает эту задачу как маркировку последовательности (sequence labeling). Модель обрабатывает весь входной текст на уровне байтов, используя архитектуру трансформера-энкодера. \n",
    "\n",
    "Для каждого символа в исходном тексте она параллельно предсказывает одно из трех действий: \n",
    "\n",
    "- K (Keep - оставить символ)\n",
    "- I (Insert - вставить пробел перед символом)\n",
    "- D (Delete - удалить символ, если это пробел). \n",
    "\n",
    "Такой подход, при котором решения для всех символов принимаются одновременно, делает модель значительно эффективнее и более чем в 900 раз быстрее предыдущих методов. В результате модель достигает высокого качества исправления при значительно меньших временных затратах."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6500c96c",
   "metadata": {},
   "source": [
    "Модель - encoder-only Transformer: \n",
    "\n",
    "эмбеддинг байтов $\\rightarrow$ усреднение в графему $\\rightarrow$ позиционное кодирование $\\rightarrow$ TransformerEncoder $\\rightarrow$ классификатор из трёх логитов (Keep/Insert/Delete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd8b439",
   "metadata": {},
   "source": [
    "Синусоидальное позиционное кодирование:\n",
    "$$\n",
    "\t\\text{PE}_{(pos, 2i)} = \\sin\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right), \\quad\n",
    "\t\\text{PE}_{(pos, 2i+1)} = \\cos\\left(\\frac{pos}{10000^{2i/d_{model}}}\\right).\n",
    "$$\n",
    "\n",
    "Экспортируем готовые матрицы на 4096 позиций и добавляем их к байтовым эмбеддингам символов,\n",
    "следуя описанию в статье по быстрому восстановлению пробелов. Это позволяет модели учитывать\n",
    "позиционную структуру текста без добавления обучаемых параметров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "77b913a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPositionalEncoding(nn.Module):\n",
    "    '''\n",
    "    Реализует классическую синусоидальную позиционную эмбеддинговую матрицу.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int\n",
    "        Размерность эмбеддингов модели.\n",
    "    max_len : int, optional\n",
    "        Максимальная длина последовательности, по умолчанию 4096.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 4096) -> None:\n",
    "        super().__init__()\n",
    "        position = torch.arange(0, max_len, dtype=torch.float32).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2, dtype=torch.float32) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Добавляет позиционные эмбеддинги к входному тензору.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Тензор формы `(batch, seq_len, d_model)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Тензор той же формы с добавленными позиционными кодировками.\n",
    "        '''\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9fc32f2",
   "metadata": {},
   "source": [
    "Encoder-only Transformer реализует составную классификацию: байты объединяются в эмбеддинг\n",
    "графемы, далее $L$ слоёв TransformerEncoder формируют контекст, а линейный слой предсказывает\n",
    "метки $\\{K, I, D\\}$. \n",
    "\n",
    "На инференсе используем жадный выбор\n",
    "\n",
    "\n",
    "$$y_i = \\argmax_{r \\in \\{K,I,D\\}} p(r \\mid x,i),$$\n",
    "\n",
    "\n",
    "дополняя его правилами из статьи: вставку $I$ разрешаем только между непробельными символами, а\n",
    "удаление $D$ - лишь для пробелов. Эти ограничения защищают от артефактов и сохраняют высокую\n",
    "точность при скорости, сравнимой с авторской реализацией из статьи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e9a0349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EOByteTransformer(nn.Module):\n",
    "    '''\n",
    "    Encoder-only Transformer, работающий на байтовых эмбеддингах.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int, optional\n",
    "        Размерность эмбеддингов.\n",
    "    nhead : int, optional\n",
    "        Количество голов внимания.\n",
    "    num_layers : int, optional\n",
    "        Число слоев TransformerEncoder.\n",
    "    dim_ff : int, optional\n",
    "        Размер скрытого слоя FFN.\n",
    "    dropout : float, optional\n",
    "        Доля дропаута.\n",
    "    max_len : int, optional\n",
    "        Максимальная длина входной последовательности в токенах.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_model: int = 512, nhead: int = 8, num_layers: int = 12,\n",
    "                 dim_ff: int = 2048, dropout: float = 0.1, max_len: int = 4096) -> None:\n",
    "        super().__init__()\n",
    "        self.byte_embed = nn.Embedding(256, d_model)\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.positional = SinusoidalPositionalEncoding(d_model, max_len=max_len)\n",
    "        self.head = nn.Linear(d_model, 3)\n",
    "\n",
    "    def forward_prepared(self, byte_values: Sequence[torch.Tensor], token_lengths: Sequence[torch.Tensor]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        Обрабатывает уже преобразованные оконные представления.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        byte_values : Sequence[torch.Tensor]\n",
    "            Список тензоров байтов для каждого примера в батче.\n",
    "        token_lengths : Sequence[torch.Tensor]\n",
    "            Список тензоров с длинами графем для каждого примера.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[torch.Tensor, torch.Tensor]\n",
    "            Логиты формы `(batch, seq_len, 3)` и маска допустимых позиций.\n",
    "        '''\n",
    "        device = self.byte_embed.weight.device\n",
    "        batch_size = len(byte_values)\n",
    "        embedding_dim = self.byte_embed.embedding_dim\n",
    "        max_tokens = max((int(lengths.numel()) for lengths in token_lengths), default=0)\n",
    "        if max_tokens == 0:\n",
    "            logits = torch.zeros((batch_size, 0, 3), device=device)\n",
    "            attn_mask = torch.zeros((batch_size, 0), dtype=torch.bool, device=device)\n",
    "            return logits, attn_mask\n",
    "        padded = torch.zeros((batch_size, max_tokens, embedding_dim), device=device)\n",
    "        attn_mask = torch.zeros((batch_size, max_tokens), dtype=torch.bool, device=device)\n",
    "        zero_vec = torch.zeros(embedding_dim, device=device)\n",
    "        for idx, (byte_tensor, len_tensor) in enumerate(zip(byte_values, token_lengths)):\n",
    "            lengths = len_tensor.to(device=device, dtype=torch.long, non_blocking=True)\n",
    "            if lengths.numel() == 0:\n",
    "                continue\n",
    "            byte_tensor = byte_tensor.to(device=device, dtype=torch.long, non_blocking=True)\n",
    "            embedded = self.byte_embed(byte_tensor)\n",
    "            pointer = 0\n",
    "            token_vectors: list[torch.Tensor] = []\n",
    "            for length in lengths.tolist():\n",
    "                if length <= 0:\n",
    "                    token_vectors.append(zero_vec)\n",
    "                    continue\n",
    "                span = embedded[pointer:pointer + length]\n",
    "                if span.numel() == 0:\n",
    "                    token_vectors.append(zero_vec)\n",
    "                else:\n",
    "                    token_vectors.append(span.mean(dim=0))\n",
    "                pointer += length\n",
    "            if not token_vectors:\n",
    "                token_vectors.append(zero_vec)\n",
    "            stacked = torch.stack(token_vectors, dim=0)\n",
    "            seq_len = stacked.size(0)\n",
    "            padded[idx, :seq_len] = stacked\n",
    "            attn_mask[idx, :seq_len] = True\n",
    "        encoded = self.positional(padded)\n",
    "        encoded = self.encoder(encoded, src_key_padding_mask=~attn_mask)\n",
    "        logits = self.head(encoded)\n",
    "        return logits, attn_mask\n",
    "\n",
    "    def forward(self, texts: Sequence[str]) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        '''\n",
    "        Обрабатывает список строк, автоматически формируя байтовые представления.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        texts : Sequence[str]\n",
    "            Список строк для обработки.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[torch.Tensor, torch.Tensor]\n",
    "            Логиты и маска допустимых позиций.\n",
    "        '''\n",
    "        byte_values: list[torch.Tensor] = []\n",
    "        token_lengths: list[torch.Tensor] = []\n",
    "        for text in texts:\n",
    "            norm_text, spans = grapheme_spans(text)\n",
    "            if not spans:\n",
    "                byte_values.append(torch.zeros(0, dtype=torch.long))\n",
    "                token_lengths.append(torch.zeros(0, dtype=torch.long))\n",
    "                continue\n",
    "            lengths = token_byte_lengths(norm_text, spans)\n",
    "            bytes_view = np.frombuffer(norm_text.encode('utf-8', errors='ignore'), dtype=np.uint8).copy()\n",
    "            byte_values.append(torch.from_numpy(bytes_view).to(torch.long))\n",
    "            token_lengths.append(torch.from_numpy(lengths.astype(np.int64, copy=True)))\n",
    "        return self.forward_prepared(byte_values, token_lengths)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def decode_positions(self, text: str, *, max_tokens: int = MAX_TOKENS,\n",
    "                         left_ctx: int = LEFT_CTX, right_ctx: int = RIGHT_CTX) -> list[int]:\n",
    "        '''\n",
    "        Выполняет авто-регрессию над одним текстом и возвращает индексы пробелов.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            Исходная строка.\n",
    "        max_tokens : int, optional\n",
    "            Ограничение длины окна.\n",
    "        left_ctx : int, optional\n",
    "            Размер левого контекста.\n",
    "        right_ctx : int, optional\n",
    "            Размер правого контекста.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[int]\n",
    "            Предсказанные позиции пробелов.\n",
    "        '''\n",
    "        norm_text, spans = grapheme_spans(text)\n",
    "        if not spans:\n",
    "            return []\n",
    "        labels: list[int] = []\n",
    "        token_lengths = token_byte_lengths(norm_text, spans)\n",
    "        encoded = norm_text.encode('utf-8', errors='ignore')\n",
    "        offsets = np.concatenate(([0], np.cumsum(token_lengths, dtype=np.int64)))\n",
    "        for win_start, win_end, core_rel_start, core_rel_end in make_token_windows(len(spans), max_tokens=max_tokens, left_ctx=left_ctx, right_ctx=right_ctx):\n",
    "            byte_start = int(offsets[win_start])\n",
    "            byte_end = int(offsets[win_end])\n",
    "            chunk_bytes = torch.from_numpy(np.frombuffer(encoded[byte_start:byte_end], dtype=np.uint8).copy()).to(torch.long)\n",
    "            chunk_lengths = torch.from_numpy(token_lengths[win_start:win_end].astype(np.int64, copy=True))\n",
    "            logits, attn = self.forward_prepared([chunk_bytes.to(DEVICE)], [chunk_lengths.to(DEVICE)])\n",
    "            preds = logits.argmax(dim=-1)[0]\n",
    "            valid = attn[0]\n",
    "            labels.extend(preds[valid].tolist()[core_rel_start:core_rel_end])\n",
    "        labels = labels[:len(spans)]\n",
    "        return labels_to_positions(norm_text, spans, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297391ee",
   "metadata": {},
   "source": [
    "### Инициализация модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69294bd9",
   "metadata": {},
   "source": [
    "P.S. Использовалась не предобученная модель, а обучение с нуля"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13d51744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:48,737 INFO: Предобученные веса отключены: модель инициализирована случайно.\n",
      "2025-09-24 17:40:48,738 INFO: Модель готова к дообучению: {'embedding': {'type': 'standard', 'embedding_dim': 512, 'dropout': 0.1, 'positional_embeddings': 'sinusoidal', 'mode': 'add_norm', 'scale_embeddings': True, 'max_length': 4096}, 'encoder': {'type': 'grouping', 'group_first': True, 'group_name': 'code_point_groups', 'group_lengths': 'lengths', 'group_padding_mask': 'padding_mask', 'encoder': {'type': 'transformer', 'dim': 512, 'heads': 8, 'num_layers': 12, 'ffw_dim': 2048, 'dropout': 0.1}}, 'head': {'type': 'sequence_classification', 'dim': 512, 'num_layers': 1, 'dropout': 0.1, 'num_classes': 3}, 'type': 'encoder_with_head'}\n",
      "2025-09-24 17:40:48,738 INFO: Модель готова к дообучению: {'embedding': {'type': 'standard', 'embedding_dim': 512, 'dropout': 0.1, 'positional_embeddings': 'sinusoidal', 'mode': 'add_norm', 'scale_embeddings': True, 'max_length': 4096}, 'encoder': {'type': 'grouping', 'group_first': True, 'group_name': 'code_point_groups', 'group_lengths': 'lengths', 'group_padding_mask': 'padding_mask', 'encoder': {'type': 'transformer', 'dim': 512, 'heads': 8, 'num_layers': 12, 'ffw_dim': 2048, 'dropout': 0.1}}, 'head': {'type': 'sequence_classification', 'dim': 512, 'num_layers': 1, 'dropout': 0.1, 'num_classes': 3}, 'type': 'encoder_with_head'}\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_model(device: str = DEVICE) -> tuple[EOByteTransformer, dict[str, object]]:\n",
    "    '''\n",
    "    Создаёт EOByteTransformer с нуля (без загрузки предобученных весов).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    device : str, optional\n",
    "        Устройство PyTorch (cpu или cuda).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[EOByteTransformer, dict[str, object]]\n",
    "        Пара из модели и словаря конфигурации (используемой для инициализации).\n",
    "    '''\n",
    "    cfg: dict[str, object] = {\n",
    "        'model': {\n",
    "            'embedding': {\n",
    "                'type': 'standard',\n",
    "                'embedding_dim': 512,\n",
    "                'dropout': 0.1,\n",
    "                'positional_embeddings': 'sinusoidal',\n",
    "                'mode': 'add_norm',\n",
    "                'scale_embeddings': True,\n",
    "                'max_length': 4096,  \n",
    "            },\n",
    "            'encoder': {\n",
    "                'type': 'grouping',\n",
    "                'group_first': True,\n",
    "                'group_name': 'code_point_groups',\n",
    "                'group_lengths': 'lengths',\n",
    "                'group_padding_mask': 'padding_mask',\n",
    "                'encoder': {\n",
    "                    'type': 'transformer',\n",
    "                    'dim': 512,\n",
    "                    'heads': 8,\n",
    "                    'num_layers': 12,\n",
    "                    'ffw_dim': 2048,\n",
    "                    'dropout': 0.1,\n",
    "                },\n",
    "            },\n",
    "            'head': {\n",
    "                'type': 'sequence_classification',\n",
    "                'dim': 512,\n",
    "                'num_layers': 1,\n",
    "                'dropout': 0.1,\n",
    "                'num_classes': 3,\n",
    "            },\n",
    "            'type': 'encoder_with_head',\n",
    "        }\n",
    "    }\n",
    "\n",
    "    d_model = 512\n",
    "    nhead = 8\n",
    "    num_layers = 12\n",
    "    dim_ff = 2048\n",
    "    dropout = 0.1\n",
    "    max_len = 4096\n",
    "\n",
    "    model = EOByteTransformer(\n",
    "        d_model=d_model,\n",
    "        nhead=nhead,\n",
    "        num_layers=num_layers,\n",
    "        dim_ff=dim_ff,\n",
    "        dropout=dropout,\n",
    "        max_len=max_len,\n",
    "    ).to(device)\n",
    "\n",
    "    logger.info('Предобученные веса отключены: модель инициализирована случайно.')\n",
    "    return model, cfg\n",
    "\n",
    "\n",
    "model, pretrained_cfg = load_pretrained_model()\n",
    "logger.info('Модель готова к дообучению: %s', pretrained_cfg.get('model', {}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8fd03f",
   "metadata": {},
   "source": [
    "### Функция потерь и метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1776f9dc",
   "metadata": {},
   "source": [
    "Используем Focal Loss с вычисленными весами, а также реализуем вспомогательную функцию для F1 по позициям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7d4b7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    '''\n",
    "    Реализация многоклассовой Focal Loss с поддержкой весов классов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gamma : float, optional\n",
    "        Параметр фокусировки. По умолчанию 2.0.\n",
    "    weight : torch.Tensor, optional\n",
    "        Весовые коэффициенты для классов.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, gamma: float = 2.0, weight: torch.Tensor | None = None) -> None:\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        if weight is not None:\n",
    "            self.register_buffer('weight', weight.detach().clone())\n",
    "        else:\n",
    "            self.weight = None\n",
    "\n",
    "    def forward(self, logits: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
    "        '''\n",
    "        Вычисляет значение функции потерь для батча.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        logits : torch.Tensor\n",
    "            Логиты формы `(N, C)`.\n",
    "        targets : torch.Tensor\n",
    "            Индексы классов формы `(N,)`.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Скалярное значение потерь.\n",
    "        '''\n",
    "        log_prob = F.log_softmax(logits, dim=-1)\n",
    "        prob = log_prob.exp()\n",
    "        weight = self.weight\n",
    "        if weight is not None and (weight.device != logits.device or weight.dtype != logits.dtype):\n",
    "            weight = weight.to(device=logits.device, dtype=logits.dtype)\n",
    "        ce = F.nll_loss(log_prob, targets, weight=weight, reduction='none')\n",
    "        pt = prob.gather(dim=1, index=targets.unsqueeze(1)).squeeze(1)\n",
    "        focal_factor = (1 - pt).pow(self.gamma)\n",
    "        return (focal_factor * ce).mean()\n",
    "\n",
    "\n",
    "def f1_positions(true_positions: Sequence[int], pred_positions: Sequence[int]) -> float:\n",
    "    '''\n",
    "    Считает F1-меру между множествами позиций пробелов.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    true_positions : Sequence[int]\n",
    "        Истинные индексы пробелов.\n",
    "    pred_positions : Sequence[int]\n",
    "        Предсказанные индексы пробелов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Значение F1 в диапазоне [0, 1].\n",
    "    '''\n",
    "    gold = set(int(p) for p in true_positions)\n",
    "    pred = set(int(p) for p in pred_positions)\n",
    "    if not gold and not pred:\n",
    "        return 1.0\n",
    "    if not gold or not pred:\n",
    "        return 0.0\n",
    "    inter = len(gold & pred)\n",
    "    precision = inter / len(pred)\n",
    "    recall = inter / len(gold)\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * precision * recall / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77a8a09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_positions_batch(model: EOByteTransformer, texts: Sequence[str], *,\n",
    "                             max_tokens: int = MAX_TOKENS, left_ctx: int = LEFT_CTX,\n",
    "                             right_ctx: int = RIGHT_CTX, batch_size: int = 64) -> list[list[int]]:\n",
    "    '''\n",
    "    Выполняет пакетное декодирование позиций пробелов для списка строк.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : EOByteTransformer\n",
    "        Обученная модель.\n",
    "    texts : Sequence[str]\n",
    "        Список строк без пробелов.\n",
    "    max_tokens : int, optional\n",
    "        Максимальная длина окна.\n",
    "    left_ctx : int, optional\n",
    "        Левый контекст.\n",
    "    right_ctx : int, optional\n",
    "        Правый контекст.\n",
    "    batch_size : int, optional\n",
    "        Размер мини-батча для декодирования.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[list[int]]\n",
    "        Список предсказанных позиций пробелов для каждой строки.\n",
    "    '''\n",
    "    predictions: list[list[int]] = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for start in range(0, len(texts), batch_size):\n",
    "            batch = texts[start:start + batch_size]\n",
    "            batch_preds = [model.decode_positions(text, max_tokens=max_tokens, left_ctx=left_ctx, right_ctx=right_ctx) for text in batch]\n",
    "            predictions.extend(batch_preds)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def evaluate_dataframe(df: pd.DataFrame, *, sample: int | None = None) -> float:\n",
    "    '''\n",
    "    Переопределенная версия оценки, использующая decode_positions_batch.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Датафрейм с колонками `no_space` и `true_positions`.\n",
    "    sample : int, optional\n",
    "        Максимальное количество строк для оценки.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Средний F1.\n",
    "    '''\n",
    "    data = df if sample is None else df.head(sample)\n",
    "    if data.empty:\n",
    "        return float('nan')\n",
    "    preds = decode_positions_batch(model, data['no_space'].tolist())\n",
    "    scores = [f1_positions(true, pred) for true, pred in zip(data['true_positions'], preds)]\n",
    "    return float(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f8ff1a",
   "metadata": {},
   "source": [
    "### Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26932b61",
   "metadata": {},
   "source": [
    "Настраиваем DataLoader, оптимизатор AdamW, планировщик OneCycle и добавляем AMP (`torch.cuda.amp`) и `torch.compile` для ускорения. Валидация проводится после каждой эпохи, лучшие веса сохраняются."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54973768",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "ACCUM_STEPS = 2\n",
    "LEARNING_RATE = 2e-4\n",
    "WEIGHT_DECAY = 0.01\n",
    "EPOCHS = 3\n",
    "VAL_BATCH_SIZE = 64\n",
    "GRAD_CLIP = 1.0\n",
    "WARMUP_STEPS = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da07035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=False,\n",
    "    num_workers=os.cpu_count() // 2 or 2,\n",
    "    pin_memory=DEVICE == 'cuda',\n",
    "    collate_fn=collate_window_batch,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0bcd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = FocalLoss(gamma=2.0, weight=CLASS_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5e925542",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b61080d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=LEARNING_RATE,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(train_loader) // ACCUM_STEPS + 1,\n",
    "    pct_start=0.1,\n",
    "    final_div_factor=10.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "661a59f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:50,278 INFO: Модель скомпилирована через torch.compile для ускорения\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.amp.GradScaler(DEVICE, enabled=AMP)\n",
    "compile_available = hasattr(torch, 'compile')\n",
    "if compile_available and DEVICE == 'cuda':\n",
    "    model = torch.compile(model)\n",
    "    logger.info('Модель скомпилирована через torch.compile для ускорения')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eed9793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model: EOByteTransformer, loader: DataLoader, optimizer: torch.optim.Optimizer,\n",
    "                     scheduler: torch.optim.lr_scheduler.LRScheduler, scaler: torch.cuda.amp.GradScaler,\n",
    "                     epoch: int) -> float:\n",
    "    '''\n",
    "    Выполняет одну эпоху обучения с градиентным накоплением и AMP.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : EOByteTransformer\n",
    "        Обучаемая модель.\n",
    "    loader : DataLoader\n",
    "        Итератор по батчам окон.\n",
    "    optimizer : torch.optim.Optimizer\n",
    "        Оптимизатор.\n",
    "    scheduler : torch.optim.lr_scheduler.LRScheduler\n",
    "        Планировщик скорости обучения.\n",
    "    scaler : torch.cuda.amp.GradScaler\n",
    "        Скалер для смешанной точности.\n",
    "    epoch : int\n",
    "        Номер текущей эпохи.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Среднее значение функции потерь по эпохе.\n",
    "    '''\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    batch_counter = 0\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    progress = tqdm(loader, desc=f'epoch {epoch}', leave=False)\n",
    "    for step, batch in enumerate(progress, start=1):\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        core_mask = batch['core_mask'].to(DEVICE)\n",
    "        byte_values = [tensor.to(DEVICE, non_blocking=True) for tensor in batch['byte_values']]\n",
    "        token_lengths = [tensor.to(DEVICE, non_blocking=True) for tensor in batch['token_lengths']]\n",
    "        with torch.amp.autocast('cuda' if DEVICE == 'cuda' else 'cpu', enabled=AMP):\n",
    "            logits, attn = model.forward_prepared(byte_values, token_lengths)\n",
    "            valid_mask = attn & core_mask\n",
    "            if valid_mask.any():\n",
    "                loss = focal_loss(logits[valid_mask], labels[valid_mask])\n",
    "            else:\n",
    "                loss = torch.zeros((), device=DEVICE)\n",
    "        loss_to_backward = loss / ACCUM_STEPS\n",
    "        scaler.scale(loss_to_backward).backward()\n",
    "        if step % ACCUM_STEPS == 0 or step == len(loader):\n",
    "            if GRAD_CLIP:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), GRAD_CLIP)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        running_loss += float(loss.item())\n",
    "        batch_counter += 1\n",
    "        progress.set_postfix({'loss': running_loss / batch_counter, 'lr': scheduler.get_last_lr()[0]})\n",
    "    return running_loss / max(1, batch_counter)\n",
    "\n",
    "\n",
    "def evaluate_model_full(model: EOByteTransformer, df: pd.DataFrame, *, batch_size: int = VAL_BATCH_SIZE) -> float:\n",
    "    '''\n",
    "    Проводит полную оценку модели на указанном датафрейме.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : EOByteTransformer\n",
    "        Обученная модель.\n",
    "    df : pd.DataFrame\n",
    "        Датафрейм для оценки.\n",
    "    batch_size : int, optional\n",
    "        Размер мини-батча при декодировании.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Средний F1.\n",
    "    '''\n",
    "    preds = decode_positions_batch(model, df['no_space'].tolist(), batch_size=batch_size)\n",
    "    scores = [f1_positions(true, pred) for true, pred in zip(df['true_positions'], preds)]\n",
    "    return float(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a21d33",
   "metadata": {},
   "source": [
    "#### Динамика обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba7400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 17:40:50,297 INFO: [train epoch 1] старт\n",
      "2025-09-24 18:37:19,412 INFO: [train epoch 1] завершено за 3389.11 c (56.49 мин)        \n",
      "2025-09-24 18:37:19,412 INFO: [validation] старт\n",
      "2025-09-24 18:39:55,423 INFO: [validation] завершено за 156.01 c (2.60 мин)\n",
      "2025-09-24 18:40:02,372 INFO: Эпоха 1: loss 0.0149, train F1 93.17, val F1 93.17\n",
      "2025-09-24 18:40:03,347 INFO: Новый лучший чекпоинт с val F1 93.17\n",
      "2025-09-24 18:40:05,953 INFO: [train epoch 2] старт\n",
      "2025-09-24 19:36:44,780 INFO: [train epoch 2] завершено за 3398.83 c (56.65 мин)          \n",
      "2025-09-24 19:36:44,780 INFO: [validation] старт\n",
      "2025-09-24 19:39:20,888 INFO: [validation] завершено за 156.11 c (2.60 мин)\n",
      "2025-09-24 19:39:27,902 INFO: Эпоха 2: loss 0.0040, train F1 95.66, val F1 95.23\n",
      "2025-09-24 19:39:29,043 INFO: Новый лучший чекпоинт с val F1 95.23\n",
      "2025-09-24 19:39:31,274 INFO: [train epoch 3] старт\n",
      "epoch 3:  94%|█████████▎| 46360/49493 [52:54<03:34, 14.63it/s, loss=0.00214, lr=1.07e-6] "
     ]
    }
   ],
   "source": [
    "best_val_f1 = -1.0\n",
    "history: list[dict[str, float]] = []\n",
    "checkpoint_dir = PROJECT_ROOT / 'experiments' / 'eo_byte_finetune'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "CKPT_PATH = checkpoint_dir / 'checkpoint_best.pt'  \n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    with timer(f'train epoch {epoch}'):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, scheduler, scaler, epoch)\n",
    "    with timer('validation'):\n",
    "        val_f1 = evaluate_model_full(model, val_df)\n",
    "    sample_train_f1 = evaluate_dataframe(train_df, sample=2_000)\n",
    "    history.append({'epoch': epoch, 'train_loss': train_loss, 'val_f1': val_f1, 'train_f1': sample_train_f1})\n",
    "    logger.info('Эпоха %d: loss %.4f, train F1 %.2f, val F1 %.2f', epoch, train_loss, sample_train_f1 * 100, val_f1 * 100)\n",
    "    payload = {\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'scheduler': scheduler.state_dict(),\n",
    "        'cfg': {\n",
    "            'd_model': pretrained_cfg.get('model', {}).get('d_model', 512),\n",
    "            'nhead': pretrained_cfg.get('model', {}).get('nhead', 8),\n",
    "            'num_layers': pretrained_cfg.get('model', {}).get('num_layers', 12),\n",
    "            'dim_ff': pretrained_cfg.get('model', {}).get('dim_ff', 2048),\n",
    "            'dropout': pretrained_cfg.get('model', {}).get('dropout', 0.1),\n",
    "        },\n",
    "    }\n",
    "    torch.save(payload, checkpoint_dir / f'checkpoint_epoch_{epoch}.pt')\n",
    "    if val_f1 > best_val_f1:\n",
    "        best_val_f1 = val_f1\n",
    "        torch.save(payload, checkpoint_dir / 'checkpoint_best.pt')\n",
    "        logger.info('Новый лучший чекпоинт с val F1 %.2f', val_f1 * 100)\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7994737",
   "metadata": {},
   "source": [
    "Визуализируем кривые потерь и метрики, чтобы убедиться в стабильном обучении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb9f3b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAEiCAYAAABkykQ1AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAT21JREFUeJzt3XlcFfX+x/HXOSwHUMANRRLFfU/NBXEvKbVuit3SrHs1b8u9paVR3jLLJfNS3SwrK1tuq1b+rLQy05DUFjFzS80lNRU3FksFN0DO/P44cuQIKgg6w+H9fDzmwcx3vvOdz5wP+jgfZrMZhmEgIiIiIiJSCnazAxARERERkfJPhYWIiIiIiJSaCgsRERERESk1FRYiIiIiIlJqKixERERERKTUVFiIiIiIiEipqbAQEREREZFSU2EhIiIiIiKlpsJCREQqrIMHD3Ls2DEAjhw5wuHDh80NSESkHFNhISIiFVZYWBiPPPIIAAMGDKBbt24mR3T52Ww2Jk6caHYYIuIFVFiIiFd49913sdlsrFq1qtC6O+64A5vNRqtWrUyITKwsMTGR+++/H4CpU6fy1ltvmRyRiEj55Wt2ACIil9L27duZOXOm2WGIRcXGxrrn27dvb2IkIiLlnwoLEfFqU6ZMwc/Pj0aNGpkdioiIiFfTpVAi4rV27NjBzJkz+ec//0l4eHiRfWbOnEmnTp0ICgqiatWq9OjRg2+++QaAqKgobDbbOaeoqCj3OMeOHeOhhx4iMjISh8NB06ZNee655zAMw2N/NpuNkSNHMmvWLJo2bUpAQADt27fnu+++8+g3ceJEbDabR9vRo0cJDw/HZrOxdOlSj3WvvfYarVq1IigoyCPGTz755Jyfz5IlS7DZbMydO7fQug8//BCbzUZycrK7bcuWLQwaNIiwsDACAwNp2rQp48aNKxRzfr+QkBCqV6/OqFGjOHnyZJGfffv27QkMDKRatWrceuut7Nmzp8hYz5WDgp/D0qVLz3nMlStX5o477vBoO3z4MKNHj3bnrFGjRjzzzDM4nU53n127dmGz2XjuuecKjdmqVSt69ep10fv//fffueWWW6hWrRpBQUF07tyZr776yqNP/phFTT/88IO739q1a+nXrx8hISFUrlyZ3r17s2LFiqI+ymIpzni5ublMmjSJxo0bExAQQPXq1enWrRuJiYnuPqmpqQwfPpw6dergcDioXbs2AwYMYNeuXRcdm4hYl85YiIjXeuqpp/D19eWRRx5hyJAhhdZPmjSJiRMn0qVLF5588kn8/f356aef+Pbbb7nuuuuYNm0aR48eBWDz5s385z//4bHHHqN58+aA68sigGEY9O/fnyVLlnDnnXfStm1bFi1axJgxY9i3bx8vvPCCx36XLVvG7NmzeeCBB3A4HLz66qv07duXlStXnvc+kKlTp5KWllaoffbs2dx333306tWL+++/n0qVKrnjPZ9evXoRGRnJrFmzGDhwoMe6WbNm0bBhQ2JiYgBYv3493bt3x8/Pj3vuuYeoqCh27NjBl19+yZQpUzy2HTRoEFFRUSQkJLBixQpeeuklDh06xPvvv+/uM2XKFJ544gkGDRrEXXfdRUZGBi+//DI9evRg7dq1VKlSpVC81157LUOHDgXg559/5qWXXjrv8Z3P8ePH6dmzJ/v27eOf//wndevWZfny5YwdO5YDBw4wbdq0ix67ONLS0ujSpQvHjx/ngQceoHr16rz33nv079+fTz75pFA+HnjgATp27OjR1rRpUwB+/fVXunfvTkhICP/+97/x8/Pj9ddfp1evXixbtozo6OgSxVbc8SZOnEhCQgJ33XUXnTp1IjMzk1WrVrFmzRquvfZaAP7617/y66+/cv/99xMVFUV6ejqJiYmkpKR4FOYi4iUMEREv8M477xiA8fPPPxuGYRg7duwwfH19jQceeMAwDMPo2bOn0bJlS3f/bdu2GXa73Rg4cKCRl5fnMZbT6Sw0/pIlSwzAWLJkSaF18+bNMwDjqaee8mi/+eabDZvNZmzfvt3dBhiAsWrVKnfb7t27jYCAAGPgwIHutgkTJhgF/4tOT083goODjX79+hWKY8iQIUaVKlWMEydOFIp3zpw5RX5e+caOHWs4HA7j8OHDHvvy9fU1JkyY4G7r0aOHERwcbOzevdtj+4KfVX7M/fv39+hz3333GYDxyy+/GIZhGLt27TJ8fHyMKVOmePTbsGGD4evrW6g9JyfHAIyRI0e62+bMmVPoczjfMVeqVMkYNmyYe3ny5MlGpUqVjN9++82j36OPPmr4+PgYKSkphmEYxs6dOw3A+O9//1tozJYtWxo9e/a8qP2PHj3aAIzvv//e3ZaVlWXUr1/fiIqKcv9OFiePcXFxhr+/v7Fjxw532/79+43g4GCjR48e59wuH+CR6+KO16ZNG+OGG24457iHDh0652cnIt5Jl0KJiFfKP1vx6KOPFrl+3rx5OJ1Oxo8fj93u+V/h2ZcgXciCBQvw8fHhgQce8Gh/6KGHMAyDr7/+2qM9JibG40bhunXrMmDAABYtWkReXl6R+5g8eTKhoaGF9gGQlZVFUFAQAQEBJYobYOjQoWRnZ3tcvjN79mxOnTrF3/72NwAyMjL47rvv+Mc//kHdunU9ti/qsxoxYoTHcv5TlxYsWADAZ599htPpZNCgQRw8eNA9hYeH07hxY5YsWeKxff5lVMU9vqysLI9xDx48WKjPnDlz6N69O1WrVvXoFxsbS15eXqFL044fP15ozHPlqjj7X7BgAZ06dfJ4vG3lypW555572LVrF5s2bSrWsebl5fHNN98QFxdHgwYN3O21a9fmtttu44cffiAzM7NYY5V0vCpVqvDrr7+ybdu2IscKDAzE39+fpUuXcujQoWLHICLllwoLEfE6v//+Ox988AH33HMPtWvXLrLPjh07sNvttGjRotT72717NxEREQQHB3u0518ytXv3bo/2xo0bFxqjSZMmHD9+nIyMjELrdu7cyeuvv86kSZOK/HIdExPD/v37mThxIikpKRw8eJAjR44UK/ZmzZrRsWNHZs2a5W6bNWsWnTt3dt/w/vvvvwMU+3G9Zx9fw4YNsdvt7uvqt23bhmEYNG7cmLCwMI9p8+bNpKene2yf/8U8NDS0WPv/xz/+UWjc/Jfg5du2bRsLFy4s1C//KVFnxzBhwoRCfbds2XLR+9+9e7f7UqaCzvU7cy4ZGRkcP378nGM5nc5z3rdS2vGefPJJDh8+TJMmTWjdujVjxoxh/fr17v4Oh4NnnnmGr7/+mlq1atGjRw+effZZUlNTix2PiJQvusdCRLzOlClT3PdWeINx48bRuHFjhg0bxvfff19o/YMPPsjWrVuZPHkykyZNKvH4Q4cOZdSoUezdu5fs7GxWrFjB9OnTyyJ0oPBZDafTic1m4+uvv8bHx6dQ//x7V/LlFyTFvSZ//PjxdO/e3aPtxhtvLBTDtddey7///e8ix2jSpInH8j333MMtt9zi0Xb33Xdf9P69QY8ePdixYweff/4533zzDW+99RYvvPACM2bM4K677gJg9OjR3HjjjcybN49FixbxxBNPkJCQwLfffku7du1MPgIRKWsqLETEq+zcuZP333+fe++9l4iIiHP2a9iwIU6nk02bNtG2bdtS7bNevXosXryYrKwsj7MW+X/Rrlevnkf/oi4d+e233wgKCiIsLMyjfe3atXz88cfMmzevyC/h4Lrk5M0332Tt2rWEhoYyYcIEfvnlFx5++OFixX/rrbcSHx/PRx99xIkTJ/Dz82Pw4MHu9fmXxGzcuLFY423bto369eu7l7dv347T6XQXBg0bNsQwDOrXr1/oC3xR8l962KFDh2Ltv3Xr1h7vpwAKfXYNGzbk6NGjhfqdS+PGjQv1rVSp0kXvv169emzdurXQtuf6nTmXsLAwgoKCzjmW3W4nMjKyWGNdzHjVqlVj+PDhDB8+nKNHj9KjRw8mTpzoLizA9Vk/9NBDPPTQQ2zbto22bdsydepUvV9GxAvpUigR8Sr/+c9/8PHxOee9Ffni4uKw2+08+eSTHo8XBQo9IvZCrr/+evLy8gr9lf+FF17AZrPRr18/j/bk5GTWrFnjXt6zZw+ff/451113XaEvoI8++ihdu3alf//+541h7NixpKSkMHPmTGJjY0v0srcaNWrQr18/Zs6cyaxZs+jbty81atRwrw8LC6NHjx68/fbbpKSkeGxb1Gf1yiuveCy//PLLAO7P4aabbsLHx4dJkyYV2t4wDP744w+Ptk8++YSmTZvSrFmzYh/ThQwaNIjk5GQWLVpUaN3hw4c5depUme2rKNdffz0rV670eJzvsWPHeOONN4iKiir2JXo+Pj5cd911fP755x6PcE1LS+PDDz+kW7duhISEFDuukox3dp4qV65Mo0aNyM7OBlz3pZz9mOGGDRsSHBzs7iMi3kVnLETEq6xbt46RI0ee92wFQKNGjRg3bhyTJ0+me/fu3HTTTTgcDn7++WciIiJISEgo9j5vvPFGrr76asaNG8euXbto06YN33zzDZ9//jmjR4+mYcOGHv1btWpFnz59PB43CxR5GdM333zDjz/+eN79L168mBdeeIEPPvig2H/pPtvQoUO5+eabAdeN4md76aWX6NatG1dddRX33HMP9evXZ9euXXz11VesW7fOo+/OnTvp378/ffv2JTk5mZkzZ3LbbbfRpk0bwPXl8qmnnmLs2LHs2rWLuLg4goOD2blzJ3PnzuWee+7h4Ycf5vfff+fZZ59l5cqV3HTTTR5/4f75558BSExMpG7duh43GhfHmDFj+OKLL/jLX/7CHXfcQfv27Tl27BgbNmzgk08+YdeuXR7FVVl79NFH+eijj+jXrx8PPPAA1apV47333mPnzp18+umnhR4ocD5PPfUUiYmJdOvWjfvuuw9fX19ef/11srOzefbZZ0scW3HHa9GiBb169aJ9+/ZUq1aNVatW8cknnzBy5EjAdRaud+/eDBo0iBYtWuDr68vcuXNJS0vj1ltvLXFcIlIOmPhEKhGRMpP/uFmHw2Hs3bu30PqzHzeb7+233zbatWtnOBwOo2rVqkbPnj2NxMTEQv3O97hZw3A9KvTBBx80IiIiDD8/P6Nx48bGf//730KPrgWMESNGGDNnzjQaN25sOBwOo127doXGzX9064ABA84bx8GDB42IiAhjyJAhRfa70ONm82VnZxtVq1Y1QkNDPR5bW9DGjRuNgQMHGlWqVDECAgKMpk2bGk888UShmDdt2mTcfPPNRnBwsFG1alVj5MiRRY756aefGt26dTMqVapkVKpUyWjWrJkxYsQIY+vWrYZhnMnphaZ33nnngsd89uNeDcOVs7FjxxqNGjUy/P39jRo1ahhdunQxnnvuOSMnJ8cwjEv3uFnDcD0S+eabb3Z/np06dTLmz5/v0ae4eVyzZo3Rp08fo3LlykZQUJBx9dVXG8uXLz/vNvk463GzxR3vqaeeMjp16mRUqVLFCAwMNJo1a2ZMmTLF/dkdPHjQGDFihNGsWTOjUqVKRmhoqBEdHW383//9X7HiEpHyx2YYJTznLyIiF81mszFixIgyvTm6LJw6dYqIiAhuvPFG/ve//13UGBMnTmTSpElkZGSUyV/73333XSZOnHjetzT36tWLO+64o9BbrUVE5PLTPRYiIsK8efPIyMhwv9laRESkpHSPhYhIBfbTTz+xfv16Jk+eTLt27ejZs6fZIbk1bNiQgQMHnrfPtddeW+geFhERMYcKCxGRCuy1115j5syZtG3blnfffdfscDx079690PsgzjZu3LjLFI2IiFyI7rEQEREREZFS0z0WIiIiIiJSaiosRERERESk1HSPRRGcTif79+8nODgYm81mdjgiIiIiIqYwDIOsrCwiIiIu+PJOFRZF2L9/P5GRkWaHISIiIiJiCXv27KFOnTrn7aPCogjBwcGA6wMMCQm57Pt3Op1kZGQQFhZ2wcpQLj/lx/qUI2tTfqxN+bE25cfavDE/mZmZREZGur8fn48KiyLkX/4UEhJiWmFx8uRJQkJCvOaX0psoP9anHFmb8mNtyo+1KT/W5s35Kc7tAd51xCIiIiIiYgoVFiIiIiIiUmoqLEREREREpNRUWIiIiIiISKmpsBARERERkVJTYWFFqRsI3DgLjh00OxIRERERkWLR42YtyPb5fYSmbcRZuyG0jDM7HBERERGRC9IZCyuq0wEA296fTQ5ERERERKR4VFhYkFGnk2tm7ypzAxERERERKSYVFlZ0heuMBQfWwakcU0MRERERESkOFRZWVL0hTkcotlMnIW2j2dGIiIiIiFyQCgsrstnJrdnGNa/LoURERESkHFBhYVE5tfILi5XmBiIiIiIiUgwqLCwqt1Y714yeDCUiIiIi5YAKC4vKrXklBjY4tAuOZpgdjoiIiIjIeamwsCjDEQxhTV0LOmshIiIiIhanwsLK6nR0/VRhISIiIiIWp8LCwoz891mosBARERERi1NhYWX5Zyz2rYG8U+bGIiIiIiJyHpYoLF555RWioqIICAggOjqalSvP/4jVOXPm0KxZMwICAmjdujULFizwWH/HHXdgs9k8pr59+17KQ7g0wpqCIwRyj0H6JrOjERERERE5J9MLi9mzZxMfH8+ECRNYs2YNbdq0oU+fPqSnpxfZf/ny5QwZMoQ777yTtWvXEhcXR1xcHBs3er6hum/fvhw4cMA9ffTRR5fjcMqWzQ5XXOWa1+VQIiIiImJhphcWzz//PHfffTfDhw+nRYsWzJgxg6CgIN5+++0i+7/44ov07duXMWPG0Lx5cyZPnsxVV13F9OnTPfo5HA7Cw8PdU9WqVS/H4ZS9Op1cP/UGbhERERGxMF8zd56Tk8Pq1asZO3asu81utxMbG0tycnKR2yQnJxMfH+/R1qdPH+bNm+fRtnTpUmrWrEnVqlW55ppreOqpp6hevXqRY2ZnZ5Odne1ezszMBMDpdOJ0Oi/m0ErF6XRiGIZr31e0xw4Ye1dimBCLFOaRH7Ek5cjalB9rU36sTfmxNm/MT0mOxdTC4uDBg+Tl5VGrVi2P9lq1arFly5Yit0lNTS2yf2pqqnu5b9++3HTTTdSvX58dO3bw2GOP0a9fP5KTk/Hx8Sk0ZkJCApMmTSrUnpGRwcmTJy/m0ErF6XRy5MgRDMPAx1GPWoDtj+2kp2zFCCinZ168SMH82O2mn/STIihH1qb8WJvyY23Kj7V5Y36ysrKK3dfUwuJSufXWW93zrVu35sorr6Rhw4YsXbqU3r17F+o/duxYj7MgmZmZREZGEhYWRkhIyGWJuSCn04nNZiMsLAy7PRyjeiNsf2wnLHs31G162eMRT5758Y7/NLyNcmRtyo+1KT/WpvxYmzfmJyAgoNh9TS0satSogY+PD2lpaR7taWlphIeHF7lNeHh4ifoDNGjQgBo1arB9+/YiCwuHw4HD4SjUbrfbTfulsNlsZ/ZfpyP8sR37vtXQtBw+3coLeeRHLEk5sjblx9qUH2tTfqzN2/JTkuMw9Yj9/f1p3749SUlJ7jan00lSUhIxMTFFbhMTE+PRHyAxMfGc/QH27t3LH3/8Qe3atcsm8MtNb+AWEREREYszvZSKj4/nzTff5L333mPz5s3ce++9HDt2jOHDhwMwdOhQj5u7R40axcKFC5k6dSpbtmxh4sSJrFq1ipEjRwJw9OhRxowZw4oVK9i1axdJSUkMGDCARo0a0adPH1OOsdTcL8pbDV50M5CIiIiIeA/T77EYPHgwGRkZjB8/ntTUVNq2bcvChQvdN2inpKR4nILp0qULH374IY8//jiPPfYYjRs3Zt68ebRq1QoAHx8f1q9fz3vvvcfhw4eJiIjguuuuY/LkyUVe7lQu1GwBfpUgOxMOboWazc2OSERERETEg+mFBcDIkSPdZxzOtnTp0kJtt9xyC7fcckuR/QMDA1m0aFFZhmc+H1/Xi/J2fQ97VqqwEBERERHLMf1SKCmmOh1cP3WfhYiIiIhYkAqL8kJv4BYRERERC1NhUV7k38CdsQVOHjE3FhERERGRs6iwKC8qh0HVKMBwPR1KRERERMRCVFiUJ/lnLfboPgsRERERsRYVFuWJXpQnIiIiIhalwqI8KVhYGIa5sYiIiIiIFKDCojyp1Qp8A+DkYfhju9nRiIiIiIi4qbAoT3z9IaKda16XQ4mIiIiIhaiwKG/yX5S3Z6W5cYiIiIiIFKDCorxx32ehF+WJiIiIiHWosChv8t/Anf4rZB81NxYRERERkdNUWJQ3IbUhpA4YTti/xuxoREREREQAFRblU6TeZyEiIiIi1qLCojzSG7hFRERExGJUWJRHelGeiIiIiFiMCovyqHYb8PGH4wfh0C6zoxERERERUWFRLvk6IPxK17zusxARERERC1BhUV5Fnn7srAoLEREREbEAFRblVf4buFVYiIiIiIgFqLAor/Jv4E7dALknzI1FRERERCo8FRblVWgkVA4H5ynYv87saERERESkglNhUV7ZbAUuh1ppbiwiIiIiUuGpsCjP8m/g/n2ZuXGIiIiISIWnwqI8a9IXbHbYkQTbFpsdjYiIiIhUYCosyrOwphB9r2t+wUO6iVtERERETKPCory7+jEIucL1Bu7v/mt2NCIiIiJSQVmisHjllVeIiooiICCA6OhoVq48/83Ic+bMoVmzZgQEBNC6dWsWLFhwzr7/+te/sNlsTJs2rYyjtghHZej3rGv+x5cgfYu58YiIiIhIhWR6YTF79mzi4+OZMGECa9asoU2bNvTp04f09PQi+y9fvpwhQ4Zw5513snbtWuLi4oiLi2Pjxo2F+s6dO5cVK1YQERFxqQ/DXM3/Ak2vB2cuzH8QnE6zIxIRERGRCsb0wuL555/n7rvvZvjw4bRo0YIZM2YQFBTE22+/XWT/F198kb59+zJmzBiaN2/O5MmTueqqq5g+fbpHv3379nH//fcza9Ys/Pz8LsehmKvfs+BXCVKWw7pZZkcjIiIiIhWMr5k7z8nJYfXq1YwdO9bdZrfbiY2NJTk5uchtkpOTiY+P92jr06cP8+bNcy87nU7+/ve/M2bMGFq2bHnBOLKzs8nOznYvZ2ZmusdxmvDXf6fTiWEYJdt3yBXQ61HsiU9gJD6B0bgPVKpx6YKswC4qP3JZKUfWpvxYm/JjbcqPtXljfkpyLKYWFgcPHiQvL49atWp5tNeqVYstW4q+VyA1NbXI/qmpqe7lZ555Bl9fXx544IFixZGQkMCkSZMKtWdkZHDy5MlijVGWnE4nR44cwTAM7PYSnFSKGkj16jPx+2MrJ7/8N0euefrSBVmBXXR+5LJRjqxN+bE25cfalB9r88b8ZGVlFbuvqYXFpbB69WpefPFF1qxZg81mK9Y2Y8eO9TgLkpmZSWRkJGFhYYSEhFyqUM/J6XRis9kICwsr+S/lgJcx3u5D4G9zcXT+B0R1uzRBVmClyo9cFsqRtSk/1qb8WJvyY23emJ+AgIBi9zW1sKhRowY+Pj6kpaV5tKelpREeHl7kNuHh4eft//3335Oenk7dunXd6/Py8njooYeYNm0au3btKjSmw+HA4XAUarfb7ab9Uthstovbf91o6DAcVr2N/at4uPdH8C18bFI6F50fuWyUI2tTfqxN+bE25cfavC0/JTkOU4/Y39+f9u3bk5SU5G5zOp0kJSURExNT5DYxMTEe/QESExPd/f/+97+zfv161q1b554iIiIYM2YMixYtunQHYyW9J0ClmvDHNtcjaEVERERELjHTL4WKj49n2LBhdOjQgU6dOjFt2jSOHTvG8OHDARg6dChXXHEFCQkJAIwaNYqePXsydepUbrjhBj7++GNWrVrFG2+8AUD16tWpXr26xz78/PwIDw+nadOml/fgzBJYBfomwKd3ul6a1+omqN7Q7KhERERExIuZfo5m8ODBPPfcc4wfP562bduybt06Fi5c6L5BOyUlhQMHDrj7d+nShQ8//JA33niDNm3a8MknnzBv3jxatWpl1iFYU6u/QoOrIS8bvnoIDMPsiERERETEi9kMQ984z5aZmUloaChHjhwx7ebt9PR0atasWbrr8/7YAa/GuIqLv/4PWt9cdkFWYGWWH7lklCNrU36sTfmxNuXH2rwxPyX5XuwdRyxFq94QeoxxzS8cCycOmxqOiIiIiHgvFRberusDUKMJHEuHpMLv6hARERERKQsqLLydrwNueN41v+pt+OEF3W8hIiIiImVOhUVFUL87dHvQNb94InwVD3mnTA1JRERERLyLCouKInYi9H0asLnOXHx8G2QfNTsqEREREfESKiwqks73wuAPwDcAti2Cd6+HrFSzoxIRERERL6DCoqJpfiMMmw9B1eHAL/BWLKRvNjsqERERESnnVFhURJEd4a7FUK0hHNkD/+sDO78zOyoRERERKcdUWFRU1Rq4iovIzpB9BD64CX6ZbXZUIiIiIlJOqbCoyIKqwdDPoeVAcObC3Htg2bN6HK2IiIiIlJgKi4rOLwD++jZ0ecC1vGQKfDES8nLNjUtEREREyhUVFgJ2O1w3GW6YCjY7rJ0Jr/eAXT+aHZmIiIiIlBMqLOSMjnfBkI8hsBqkb3I9jvazeyArzezIRERERMTiVFiIpyZ94P7V0H44YIP1s2F6B1jxmt7WLSIiIiLnpMJCCguqBjdOg7uTIKIdZGfCwkfhjZ6wO9ns6ERERETEglRYyLld0R7uSoK/TIPAqpC2Ed7pC3P/BUfTzY5ORERERCxEhYWcn90HOgyHkavhqmGADX75CF7uAD+9rsujRERERARQYSHFVak69H/J9VK92m1dL9X7+t+uy6N2LDE7OhERERExmQoLKZk6HeDub+GG5yGgiuvyqA/i4MPBkPGb2dGJiIiIiElUWEjJ2X2g453wwFqI/hfYfeG3hfBqZ1gwBo79YXaEIiIiInKZXVRhsWfPHvbu3eteXrlyJaNHj+aNN94os8CkHAiqBv2egftWQNPrwciDlW/AS+1g+ctwKtvsCEVERETkMrmowuK2225jyRLXdfWpqalce+21rFy5knHjxvHkk0+WaYBSDtRoDEM+gqFfQHhr1/0X3zwOr3SCTZ+DYZgdoYiIiIhcYhdVWGzcuJFOnToB8H//93+0atWK5cuXM2vWLN59992yjE/KkwY94Z5lMOAVqBwOh3bB/w2Fd/rBvtVmRyciIiIil9BFFRa5ubk4HA4AFi9eTP/+/QFo1qwZBw4cKLvopPyx+0C7v7ne3t3zEfANhJRkePMamB8PJzPNjlBERERELoGLKixatmzJjBkz+P7770lMTKRv374A7N+/n+rVq5dpgFJOOSrD1Y+5Cow2Q1xtq/4Hr8bAtkRzYxMRERGRMndRhcUzzzzD66+/Tq9evRgyZAht2rQB4IsvvnBfIiUCQOgVMHCG6/6LqlGQuRdm3Qyf/ROO/2l2dCIiIiJSRnwvZqNevXpx8OBBMjMzqVq1qrv9nnvuISgoqMyCEy/SoCfcmwxLpsCKV2H9x7B9MVz/X2g5EGw2syMUERERkVK4qDMWJ06cIDs7211U7N69m2nTprF161Zq1qxZ4vFeeeUVoqKiCAgIIDo6mpUrV563/5w5c2jWrBkBAQG0bt2aBQsWeKyfOHEizZo1o1KlSlStWpXY2Fh++umnEsclZcw/CPpMgTsTIawZHD8InwyH2X+DTN2bIyIiIlKeXVRhMWDAAN5//30ADh8+THR0NFOnTiUuLo7XXnutRGPNnj2b+Ph4JkyYwJo1a2jTpg19+vQhPT29yP7Lly9nyJAh3Hnnnaxdu5a4uDji4uLYuHGju0+TJk2YPn06GzZs4IcffiAqKorrrruOjIyMizlcKWt1OsA/v4Oej7perrdlPrwSDWve16NpRURERMopm2GU/JtcjRo1WLZsGS1btuStt97i5ZdfZu3atXz66aeMHz+ezZs3F3us6OhoOnbsyPTp0wFwOp1ERkZy//338+ijjxbqP3jwYI4dO8b8+fPdbZ07d6Zt27bMmDGjyH1kZmYSGhrK4sWL6d279wVjyu9/5MgRQkJCin0sZcXpdJKenk7NmjWx27385ehpv8LnI2D/Wtdy/Z5w44tQrb65cZ1HhcpPOaUcWZvyY23Kj7UpP9bmjfkpyffiizri48ePExwcDMA333zDTTfdhN1up3PnzuzevbvY4+Tk5LB69WpiY2PPBGS3ExsbS3JycpHbJCcne/QH6NOnzzn75+Tk8MYbbxAaGuq+yVwspFZLuHMxXPcU+AbAzmXwamf47jk4lWN2dCIiIiJSTBd183ajRo2YN28eAwcOZNGiRTz44IMApKenl+gv/AcPHiQvL49atWp5tNeqVYstW7YUuU1qamqR/VNTUz3a5s+fz6233srx48epXbs2iYmJ1KhRo8gxs7Ozyc7Odi9nZrreteB0OnE6ncU+nrLidDoxDMOUfZvCZofOI6BJP2zzR2Pb9T18Oxlj/WyM66dCVDezI/RQ4fJTDilH1qb8WJvyY23Kj7V5Y35KciwXVViMHz+e2267jQcffJBrrrmGmJgYwHX2ol27dhczZJm7+uqrWbduHQcPHuTNN99k0KBB/PTTT0XeXJ6QkMCkSZMKtWdkZHDy5MnLEa4Hp9PJkSNHMAzDa06jFU9l6PMmAdu+JDj5aXwO/obt/Rs50WQAWTGP4Ay0xjtSKm5+yg/lyNqUH2tTfqxN+bE2b8xPVlZWsfteVGFx8803061bNw4cOOBxeVHv3r0ZOHBgscepUaMGPj4+pKWlebSnpaURHh5e5Dbh4eHF6l+pUiUaNWpEo0aN6Ny5M40bN+Z///sfY8eOLTTm2LFjiY+Pdy9nZmYSGRlJWFiYafdY2Gw2wsLCvOaXskRq3QXtb8ZYMhlWvUPgb58TkLIUo/cEuGqY6wyHiSp8fsoB5cjalB9rU36sTfmxNm/MT0BAQLH7XlRhAa4v+OHh4ezduxeAOnXqlPjleP7+/rRv356kpCTi4uIAV0KSkpIYOXJkkdvExMSQlJTE6NGj3W2JiYnusybn4nQ6PS53KsjhcOBwOAq12+12034pbDabqfs3XaVq8JcXoO3fYP5obKnrsX0VD798BDc8D7WvNDW8Cp+fckA5sjblx9qUH2tTfqzN2/JTkuO4qCN2Op08+eSThIaGUq9ePerVq0eVKlWYPHlyia8pi4+P58033+S9995j8+bN3HvvvRw7dozhw4cDMHToUI+zDKNGjWLhwoVMnTqVLVu2MHHiRFatWuUuRI4dO8Zjjz3GihUr2L17N6tXr+Yf//gH+/bt45ZbbrmYwxUz1WkPdy+Bvk+DfzDs/Rne6AkLx0J28U/NiYiIiMildVFnLMaNG8f//vc/nn76abp27QrADz/8wMSJEzl58iRTpkwp9liDBw8mIyOD8ePHk5qaStu2bVm4cKH7Bu2UlBSPSqlLly58+OGHPP744zz22GM0btyYefPm0apVKwB8fHzYsmUL7733HgcPHqR69ep07NiR77//npYtW17M4YrZfHyh873QYoCroNg0z/X27l/nwjWPQ5shYPcxO0oRERGRCu2i3mMRERHBjBkz6N+/v0f7559/zn333ce+ffvKLEAz6D0WFrdtMSx4GA7tdC3XagXXPgmNLvyOkrKg/FifcmRtyo+1KT/WpvxYmzfm55K/x+LPP/+kWbNmhdqbNWvGn3/+eTFDihRf41i4bwVcOxkCQiFtI8y8CT4YCKkbL7y9iIiIiJS5iyos2rRp435TdkHTp0/nyivNvalWKgi/AOj6ADywzvUODLsf7PgWZnSDeSMgc7/ZEYqIiIhUKBd1j8Wzzz7LDTfcwOLFi91PY0pOTmbPnj0sWLCgTAMUOa+gatD3P9DpLkh60nXfxbqZsPFTiBkB3UaDI9jsKEVERES83kWdsejZsye//fYbAwcO5PDhwxw+fJibbrqJX3/9lQ8++KCsYxS5sGoN4JZ34a4kqBsDp07A98/BS+3g57cgL9fsCEVERES82kXdvH0uv/zyC1dddRV5eXllNaQpdPN2OWcYsOUrSBwPf+5wtVWpBz0edj1BysevVMMrP9anHFmb8mNtyo+1KT/W5o35ueQ3b4tYms0Gzf8CI36C65+DSmFweDd8cT+8dBWsegdO5ZgdpYiIiIhXUWEh3svHDzrdDaPWQ5//QOVacCQF5o8+c4nUqaLfxi4iIiIiJaPCQryff5DrRu5Rv0DfZ6ByOGTuha8eghfbwk9vQO5Js6MUERERKddK9FSom2666bzrDx8+XJpYRC4tv0Do/C9ofweseR9+eAGy9sPXY+CH56HraGg/zNVPREREREqkRIVFaGjoBdcPHTq0VAGJXHJ+ARB9j6uIWPsBfP+C6wzGwkfgu/9Ch3+4ppDaZkcqIiIiUm6UqLB45513LlUcIpefrwM63gXt/g7rZrkKjCMp8N2zrjMYLQdC9L1Qp73ZkYqIiIhYnu6xEPF1uM5QPLDW9S6MyM7gPAUb5sBb18BbsbDhE70LQ0REROQ8VFiI5PPxdZ2luHMR3LMUrrwV7H6w92f49E6Y1tp1qdSxg2ZHKiIiImI5KixEihLRDm56HR78FXqNhUo1IesAfPsUtmmtCFn6GOxd5XoZn4iIiIiosBA5r+Ba0OtReHAjDHwDItphy8smaMun2N++Fl6NgeXT4WiG2ZGKiIiImEqFhUhx+DqgzWC4ewnO4Qs50bg/hm8gZGyGb8bB881g9t/gt0WQd8rsaEVEREQuuxI9FUqkwrPZIDKaI73r4whxYNs0F9Z8APvXwOYvXVNwbWgzBNr9Dao3NDtiERERkctCZyxELlZAqOtpUvcsgXuXQ+f7ILCa616MH56Hl6+Cd653vYzv+J9mRysiIiJySamwECkLtVpC3wR4aCvc8h40uhZsdtj9I3xxPzzXGGbeDGtnwYlDZkcrIiIiUuZ0KZRIWfL1h5ZxrunIPvjlI/h1HqRtgO2JrulLP2h4DbS6CZr2c535EBERESnnVFiIXCqhV0CPh11Txm+waR78OhfSN8G2Ra7Jxx8axbren9GkLwSEmB21iIiIyEVRYSFyOYQ1gZ7/dk3pW1xFxsbP4OBW2LrANfn4Q/2errMYTftBSITZUYuIiIgUmwoLkcutZjOo+Sj0fATSN7vOYvz6Gfyx/czlUl/FQ+220PR6V5ER3tr1RCoRERERi1JhIWIWmw1qtXBNVz8GB3+DLV/B1q9h789wYJ1rWvofCKlz5kxGVHfXvRwiIiIiFqLCQsQKbDYIa+qausfD0XTXy/a2fg07voXMvfDzm67JPxga9HTdAN7waqjWwOzoRURERFRYiFhS5Zpw1d9dU+4J+H0ZbP0Kti6EY+mwZb5rAqgadbrIuMZ1NiOwipmRi4iISAWlwkLE6vwCoWlf1+R0wv618Pu3sGMJ7PkJDu2CVW+7JpsdruhwptC4oj346J+5iIiIXHr6xiFSntjtUKe9a+oxBrKzYNePrsuldnwLf2yDvStd07Knwb8yRHaCel2gbhdXoeEXYPZRiIiIiBeyxJu3X3nlFaKioggICCA6OpqVK1eet/+cOXNo1qwZAQEBtG7dmgULFrjX5ebm8sgjj9C6dWsqVapEREQEQ4cOZf/+/Zf6MEQuP0ew60zG9c/C/atg9Ebo/7LrvRiBVSHnqKvg+PYpePd6eDoS3u4LSU/CtsVwMtPsIxAREREvYfoZi9mzZxMfH8+MGTOIjo5m2rRp9OnTh61bt1KzZs1C/ZcvX86QIUNISEjgL3/5Cx9++CFxcXGsWbOGVq1acfz4cdasWcMTTzxBmzZtOHToEKNGjaJ///6sWrXKhCMUuYyqRMJVQ12T0+l6Gd/u5ZCy3PXzaBqkJLsmprounQpv7TqbEdnJNYXWMfsoREREpByyGYZhmBlAdHQ0HTt2ZPr06QA4nU4iIyO5//77efTRRwv1Hzx4MMeOHWP+/Pnuts6dO9O2bVtmzJhR5D5+/vlnOnXqxO7du6lbt+4FY8rMzCQ0NJQjR44QEnL534TsdDpJT0+nZs2a2O2WOKkkBZTb/BgG/Pm7q8DILzYO7SrcLzgC6nSAOh1dhUbtNq77PMqRcpujCkL5sTblx9qUH2vzxvyU5HuxqWcscnJyWL16NWPHjnW32e12YmNjSU5OLnKb5ORk4uPjPdr69OnDvHnzzrmfI0eOYLPZqFKlSpHrs7Ozyc7Odi9nZrouD3E6nTidzmIeTdlxOp0YhmHKvuXCynV+qtZ3TW1vdy1n7oeUZGwpybBvFaRuxJa1HzZ/4ZoAw+7nOqtRpwNGnY4Q0d71JCoLv7CvXOeoAlB+rE35sTblx9q8MT8lORZTC4uDBw+Sl5dHrVq1PNpr1arFli1bitwmNTW1yP6pqalF9j958iSPPPIIQ4YMOWeVlZCQwKRJkwq1Z2RkcPLkyeIcSplyOp0cOXIEwzC8ptr1Jt6VH1+o2d01dQBb7nF8M37FP20tfmm/4Je2Dp8TB2H/Gti/BtvKNwBwOkLJrdGS3LCW5Ia14lRYS/KC61im2PCuHHkf5cfalB9rU36szRvzk5WVVey+pt9jcSnl5uYyaNAgDMPgtddeO2e/sWPHepwFyczMJDIykrCwMNMuhbLZbISFhXnNL6U38fr8XBEF3OCaNwycR/bA3pXY9q5yvRE8bSP27CM49i3HsW+5ezMjsCrUbge122BEuH4SGmlKseH1OSrnlB9rU36sTfmxNm/MT0BA8Z8maWphUaNGDXx8fEhLS/NoT0tLIzw8vMhtwsPDi9U/v6jYvXs333777XkLBIfDgcPhKNRut9tN+6Ww2Wym7l/Or0Llp1qUa7pykGv5VI7rpvAD61zv1Ni/FtI2YTtxyPV+jd+/xV1KBFZ1XUYVfuXpqTXUaHJZ3q1RoXJUDik/1qb8WJvyY23elp+SHIephYW/vz/t27cnKSmJuLg4wFXpJSUlMXLkyCK3iYmJISkpidGjR7vbEhMTiYmJcS/nFxXbtm1jyZIlVK9e/VIehkjF4usPEW1dU/s7XG2nsiHt1zOFxoF1kL4ZThyCnd+5pnw+DqjV4kyhEX6la9kRfPmPRURERMqM6ZdCxcfHM2zYMDp06ECnTp2YNm0ax44dY/jw4QAMHTqUK664goSEBABGjRpFz549mTp1KjfccAMff/wxq1at4o03XNd+5+bmcvPNN7NmzRrmz59PXl6e+/6LatWq4e/vb86BingzXwdccZVrypd7EjK2QOoGSF1/+ucG17s18guQgkIjoWZzCGsGNVtAzWZQoyn4B13eYxEREZGLYnphMXjwYDIyMhg/fjypqam0bduWhQsXum/QTklJ8TgF06VLFz788EMef/xxHnvsMRo3bsy8efNo1aoVAPv27eOLL1xPs2nbtq3HvpYsWUKvXr0uy3GJVHh+AWfObORzOuHQTs9C48B6OJoKR/a4pm3fFBjE5noCVc3mrqlKPfCvdGbyy58POjPvW/iyRhEREbn0TH+PhRXpPRZyPsrPJXD8T9fZjfTNrilji+s+juN/lHwsmx0jqDqHeiVQpf1flSML0r8ha1N+rE35sTZvzE+5eY+FiAgAQdWgXhfXVNDRDMjYDOmnC42sA5BzzDXlHoec465Lq3KPw6nTj4Y2nNiOZRC04QNo/9fLfywiIiIVlAoLEbGuymGuqX6PC/d15rkKjrRf4Z2+OPYlY+QcgwDdFC4iInI5eMc5GhERuw8EhEDdzhhV6mLLy4Gdy8yOSkREpMJQYSEi3sVmg8Z9XLMeN4KLiIjIpaTCQkS8jtGkr2vmt0WuJ1GJiIjIJafCQkS8T72uOP2CsB1NhdRfzI5GRESkQlBhISLex9dBTp1urvmtC82NRUREpIJQYSEiXim7Xi/XzG8qLERERC4HFRYi4pWy6/bEwAYH1kHmAbPDERER8XoqLETEKzmDasAV7V0LOmshIiJyyamwEBGvZTRxPXaW3xaZG4iIiEgFoMJCRLzX6fdZ8PtSyD1haigiIiLeToWFiHivWq0gpA6cOgE7vzM7GhEREa+mwkJEvJfNBvmXQ2392txYREREvJwKCxHxbk37uX7+tggMw9xYREREvJgKCxHxblHdwS8IsvZD6nqzoxEREfFaKixExLv5BUCDq13zejqUiIjIJaPCQkS8n+6zEBERueRUWIiI98svLPavgaw0c2MRERHxUiosRMT7BYdDRDvX/DZdDiUiInIpqLAQkYqhSYGnQ4mIiEiZU2EhIhVD/uVQO76F3JPmxiIiIuKFVFiISMVQuw0E14bc47DrB7OjERER8ToqLESkYij4Fu7f9HQoERGRsqbCQkQqjiZ6C7eIiMilosJCRCqO+j3ANwCO7IG0X82ORkRExKuosBCRisM/CBr0cs3/ttDUUERERLyN6YXFK6+8QlRUFAEBAURHR7Ny5crz9p8zZw7NmjUjICCA1q1bs2DBAo/1n332Gddddx3Vq1fHZrOxbt26Sxi9iJQ77vssVFiIiIiUJVMLi9mzZxMfH8+ECRNYs2YNbdq0oU+fPqSnpxfZf/ny5QwZMoQ777yTtWvXEhcXR1xcHBs3bnT3OXbsGN26deOZZ565XIchIuVJk76un3tXwdEMc2MRERHxIqYWFs8//zx33303w4cPp0WLFsyYMYOgoCDefvvtIvu/+OKL9O3blzFjxtC8eXMmT57MVVddxfTp0919/v73vzN+/HhiY2Mv12GISHkSEgHhVwIGbPvG7GhERES8hmmFRU5ODqtXr/YoAOx2O7GxsSQnJxe5TXJycqGCoU+fPufsLyJSpKb5T4fS5VAiIiJlxdesHR88eJC8vDxq1arl0V6rVi22bNlS5DapqalF9k9NTS1VLNnZ2WRnZ7uXMzMzAXA6nTidzlKNfTGcTieGYZiyb7kw5cf6LpijRtdhX/YMxo5vMXJOgK/j8gZYwenfkLUpP9am/FibN+anJMdiWmFhJQkJCUyaNKlQe0ZGBidPnrzs8TidTo4cOYJhGNjtpt9fL2dRfqzvgjnyjSAsKAyf4xkc+mUBOZFdL3+QFZj+DVmb8mNtyo+1eWN+srKyit3XtMKiRo0a+Pj4kJaW5tGelpZGeHh4kduEh4eXqH9xjR07lvj4ePdyZmYmkZGRhIWFERISUqqxL4bT6cRmsxEWFuY1v5TeRPmxvuLkyNa0L6z9gKoHlmE07Qo2e4HJBnYfzzZsBbY+6+V6Z79sz2YDm8+ZscSD/g1Zm/JjbcqPtXljfgICAord17TCwt/fn/bt25OUlERcXBzgSkZSUhIjR44scpuYmBiSkpIYPXq0uy0xMZGYmJhSxeJwOHA4Cl8KYbfbTfulsNlspu5fzk/5sb4L5qhpP1j7AbY172Fb894lDCS/OPE5XaycLjjsdrD7uS7D8nWAj+PM/DmXA8DX//TPs/sEnPnpFwi+ga6ffgHgF3S6PQh8/CxR7OjfkLUpP9am/Fibt+WnJMdh6qVQ8fHxDBs2jA4dOtCpUyemTZvGsWPHGD58OABDhw7liiuuICEhAYBRo0bRs2dPpk6dyg033MDHH3/MqlWreOONN9xj/vnnn6SkpLB//34Atm7dCrjOdpT2zIaIeJGG10DtNpC6AYxLeC2s4Tw9/inIu3S7KTab3bPQ8As8awrynM8vWOx+4ON7+ufpKX/e7nu6zd81uYue00XQ2W12v8JneUREpNwztbAYPHgwGRkZjB8/ntTUVNq2bcvChQvdN2inpKR4VEldunThww8/5PHHH+exxx6jcePGzJs3j1atWrn7fPHFF+7CBODWW28FYMKECUycOPHyHJiIWJ9fIPzzuzPLhnGmCDjXVPByqEJ/9S+wnN/fmQdG3pmf7rbTP525cCoH8rLh1EnX/KmTkJcDp7ILzJ+9rsCyR9vpbXJPQO5JyD1+evn4meLJcELOUddkEjtQC9uZgqNg0eHx01GgWPE/M+/j51rvUcycvf4C83bfAm35RZK/q3jy8T9TNFng7I6ISHlhMwz92ehsmZmZhIaGcuTIEdPusUhPT6dmzZpecxrNmyg/1qccncUwIC/Xs9AoWHzknoBTJ063HS/w8/T6vBzX9s5TZ83nupYLzucXRXnZBYqm0z+dp8z+JEou/3I1dzFzuhg5u61gYZNfKLn7FWw/q4jxOOvjX2D9WQXOhYogu6/r8royoH8/1qb8WJs35qck34v1VCgREW9ns52+LMnf3DiceZCXgzPnBAfT9lGjSjB256nTxUd2gaKk4BmbAgWLe8ot0Dd/fTbknTp337ycMwVO3inX2aK805OzwM9CMedCThHtVmSzny4w8i9b8z1TdBRc9pgvcCmb3dVus/sRmpOLLSDAdV8QtgL3CuH5QIOq9aDjXeAINvngRcQKVFiIiMjlYfcBeyD4OHAG5UCVmmX2V/YyYRieZ2WKKmpO5RQoZAoWODkUKozycj2LprPHzT/TU1SRU+R8zpniqagiyHCe2U8paiEbEFiSDZJfhd7joe3t1sqniFx2KixERETAdWYn/3Ijqzu7CMq/Z8ddrJxj2V2kFDhrc9Y656lcjmYdoXKlSthtnL5n6PQ9SBhnlp2nYMMc+PN3+GIk/Pwm9H0a6nUx+9MREZOosBARESlvLmUR5HRyPD2dyjWLcUap+0Ow8g1Y9iwc+AXe6QctB0LsJNdlUiJSoeicpYiIiFwcXwd0uR/uXwPt7wBs8OtcmN4RkiZDtnlPHxORy0+FhYiIiJRO5TC48UX41/cQ1d11b8n3z8HL7WHdh+C8hO+KERHL0KVQIiIiUjbCW8OwL2HLfPjmcTi0C+bdCz+9DpHRrqdHOYIhIAQcIWeWHcFnlu2+rvs3nHmun0ae57J7yiv0RCv35ON3+mEBBR7lqxvLRS45FRYiIiJSdmw2aH4jNLoWfnoNvnsODqxzTWay+571fpGzX8p4erLZwOZz5rG69gLzBSd3++mfdvtZywW2g9PztjOP6s1f9nicb4E+55qAwKNHYU9oEY8DLmL8gnHafU7/tBduK0kM+S+OLLTPs/d/1ufg3n/+Pm16CaWXUWEhIiIiZc8vALo9CG1ug42fwvE/IDsTsrNOT5lwsuBylutFjQXZfM46G1Fg2WY/feYi/+lXp84sG0VcepV/pqOcvJbkXOxAqNlBlKWCxVihouasAie/ePH4WbBA48y6QuMWLP6K2KdHYcQ5xs8vgmwF+ngu2wyDKjk52AICiz6OswvBc43lMWuDag2ge3zZfe6XiAoLERERuXSCa0HMfcXreyrHVRTkFxEX+9dsp7PAJVOnH6Vb1PtGzn73iDP3zKN1Dafrcqv8eSOvwKN28zzbPPo5C683DFyP6jWKfnQvp8ekwL7PEYfhzCM7+yQOf39sFDXeWdsaxunLyfIK/Cw4bt7593325HSeOZaCx2AUaM/vi3HhXLn7egcbEHApBo6MVmEhIiIiUmxl9XZ4ux3s/oDJb5u/BAynk8Pp6dSsWROb1e8byS8yChU1ea4C5exC57zFkdOzeClUVHHWunMVekYRBaNReNyC8RdsO3s+v9/pZafTSVZmJsHBlbGfXTx6FGn5Yxc1ThFtIRFlk5NLTIWFiIiIiJS9/PtV7D5mR3L5OJ2cSE8nuDjvgfFCFe+IRURERESkzKmwEBERERGRUlNhISIiIiIipabCQkRERERESk2FhYiIiIiIlJoKCxERERERKTU9brYIxulnBmdmZpqyf6fTSVZWFgEBAdgr4KPKrE75sT7lyNqUH2tTfqxN+bE2b8xP/vdhw+M9G0VTYVGErKwsACIjI02ORERERETEfFlZWYSGhp63j80oTvlRwTidTvbv309wcDA2m+2y7z8zM5PIyEj27NlDSEjIZd+/nJ/yY33KkbUpP9am/Fib8mNt3pgfwzDIysoiIiLigmdhdMaiCHa7nTp16pgdBiEhIV7zS+mNlB/rU46sTfmxNuXH2pQfa/O2/FzoTEU+77j4S0RERERETKXCQkRERERESk2FhQU5HA4mTJiAw+EwOxQpgvJjfcqRtSk/1qb8WJvyY20VPT+6eVtEREREREpNZyxERERERKTUVFiIiIiIiEipqbAQEREREZFSU2FhQa+88gpRUVEEBAQQHR3NypUrzQ6pQvruu++48cYbiYiIwGazMW/ePI/1hmEwfvx4ateuTWBgILGxsWzbts2cYCughIQEOnbsSHBwMDVr1iQuLo6tW7d69Dl58iQjRoygevXqVK5cmb/+9a+kpaWZFHHF8tprr3HllVe6n+UeExPD119/7V6v3FjL008/jc1mY/To0e425cg8EydOxGazeUzNmjVzr1duzLdv3z7+9re/Ub16dQIDA2ndujWrVq1yr6+o3xFUWFjM7NmziY+PZ8KECaxZs4Y2bdrQp08f0tPTzQ6twjl27Bht2rThlVdeKXL9s88+y0svvcSMGTP46aefqFSpEn369OHkyZOXOdKKadmyZYwYMYIVK1aQmJhIbm4u1113HceOHXP3efDBB/nyyy+ZM2cOy5YtY//+/dx0000mRl1x1KlTh6effprVq1ezatUqrrnmGgYMGMCvv/4KKDdW8vPPP/P6669z5ZVXerQrR+Zq2bIlBw4ccE8//PCDe51yY65Dhw7RtWtX/Pz8+Prrr9m0aRNTp06latWq7j4V9juCIZbSqVMnY8SIEe7lvLw8IyIiwkhISDAxKgGMuXPnupedTqcRHh5u/Pe//3W3HT582HA4HMZHH31kQoSSnp5uAMayZcsMw3Dlw8/Pz5gzZ467z+bNmw3ASE5ONivMCq1q1arGW2+9pdxYSFZWltG4cWMjMTHR6NmzpzFq1CjDMPTvx2wTJkww2rRpU+Q65cZ8jzzyiNGtW7dzrq/I3xF0xsJCcnJyWL16NbGxse42u91ObGwsycnJJkYmZ9u5cyepqakeuQoNDSU6Olq5MsmRI0cAqFatGgCrV68mNzfXI0fNmjWjbt26ytFllpeXx8cff8yxY8eIiYlRbixkxIgR3HDDDR65AP37sYJt27YRERFBgwYNuP3220lJSQGUGyv44osv6NChA7fccgs1a9akXbt2vPnmm+71Ffk7ggoLCzl48CB5eXnUqlXLo71WrVqkpqaaFJUUJT8fypU1OJ1ORo8eTdeuXWnVqhXgypG/vz9VqlTx6KscXT4bNmygcuXKOBwO/vWvfzF37lxatGih3FjExx9/zJo1a0hISCi0TjkyV3R0NO+++y4LFy7ktddeY+fOnXTv3p2srCzlxgJ+//13XnvtNRo3bsyiRYu49957eeCBB3jvvfeAiv0dwdfsAERESmvEiBFs3LjR4xpkMV/Tpk1Zt24dR44c4ZNPPmHYsGEsW7bM7LAE2LNnD6NGjSIxMZGAgACzw5Gz9OvXzz1/5ZVXEh0dTb169fi///s/AgMDTYxMwPXHrA4dOvCf//wHgHbt2rFx40ZmzJjBsGHDTI7OXDpjYSE1atTAx8en0JMd0tLSCA8PNykqKUp+PpQr840cOZL58+ezZMkS6tSp424PDw8nJyeHw4cPe/RXji4ff39/GjVqRPv27UlISKBNmza8+OKLyo0FrF69mvT0dK666ip8fX3x9fVl2bJlvPTSS/j6+lKrVi3lyEKqVKlCkyZN2L59u/79WEDt2rVp0aKFR1vz5s3dl6tV5O8IKiwsxN/fn/bt25OUlORuczqdJCUlERMTY2Jkcrb69esTHh7ukavMzEx++ukn5eoyMQyDkSNHMnfuXL799lvq16/vsb59+/b4+fl55Gjr1q2kpKQoRyZxOp1kZ2crNxbQu3dvNmzYwLp169xThw4duP32293zypF1HD16lB07dlC7dm39+7GArl27Fnq8+W+//Ua9evWACv4dwey7x8XTxx9/bDgcDuPdd981Nm3aZNxzzz1GlSpVjNTUVLNDq3CysrKMtWvXGmvXrjUA4/nnnzfWrl1r7N692zAMw3j66aeNKlWqGJ9//rmxfv16Y8CAAUb9+vWNEydOmBx5xXDvvfcaoaGhxtKlS40DBw64p+PHj7v7/Otf/zLq1q1rfPvtt8aqVauMmJgYIyYmxsSoK45HH33UWLZsmbFz505j/fr1xqOPPmrYbDbjm2++MQxDubGigk+FMgzlyEwPPfSQsXTpUmPnzp3Gjz/+aMTGxho1atQw0tPTDcNQbsy2cuVKw9fX15gyZYqxbds2Y9asWUZQUJAxc+ZMd5+K+h1BhYUFvfzyy0bdunUNf39/o1OnTsaKFSvMDqlCWrJkiQEUmoYNG2YYhutxck888YRRq1Ytw+FwGL179za2bt1qbtAVSFG5AYx33nnH3efEiRPGfffdZ1StWtUICgoyBg4caBw4cMC8oCuQf/zjH0a9evUMf39/IywszOjdu7e7qDAM5caKzi4slCPzDB482Khdu7bh7+9vXHHFFcbgwYON7du3u9crN+b78ssvjVatWhkOh8No1qyZ8cYbb3isr6jfEWyGYRjmnCsRERERERFvoXssRERERESk1FRYiIiIiIhIqamwEBERERGRUlNhISIiIiIipabCQkRERERESk2FhYiIiIiIlJoKCxERERERKTUVFiIiIiIiUmoqLEREREREpNRUWIiIWMQdd9xBXFycR1tGRgatWrUiOjqaI0eOmBOYiIhIMaiwEBGxqIyMDK655hoCAwP55ptvCA0NNTskERGRc1JhISJiQQcPHqR37944HA4SExM9ioqUlBQGDBhA5cqVCQkJYdCgQaSlpbnXT5w4kbZt23qMt3TpUmw2G4cPH3bPn2sCePfdd6lSpQrz5s2jcePGBAQE0KdPH/bs2eMx7muvvUbDhg3x9/enadOmfPDBB4WO5Y477ii0j9GjR7vX22w25s2bd87PIioqimnTphUas+DZnV69enmMWdDo0aPp1auXe9npdJKQkED9+vUJDAykTZs2fPLJJ+fcf1ExTJs2jaioKI8+Zx/HI488QpMmTQgKCqJBgwY88cQT5ObmutdPnDix0OdSo0YNAHbt2oXNZmPdunXu/k888QQ2m63QZyEiYhUqLERELOaPP/4gNjYWX19fEhMTqVKlinud0+lkwIAB/PnnnyxbtozExER+//13Bg8eXOzxu3TpwoEDBzhw4ACffvopgHv5wIED7n7Hjx9nypQpvP/++/z4448cPnyYW2+91b1+7ty5jBo1ioceeoiNGzfyz3/+k+HDh7NkyRKP/RmGQd++fd3jx8TEXOQnUzYSEhJ4//33mTFjBr/++isPPvggf/vb31i2bFmZ7ic4OJh3332XTZs28eKLL/Lmm2/ywgsvePRp2bKlx2e/adOmIsfau3cv06ZNIzAwsExjFBEpS75mByAiImccOnSI2NhYNm3aRPv27QkJCfFYn5SUxIYNG9i5cyeRkZEAvP/++7Rs2ZKff/6Zjh07XnAf/v7+hIeHA1CtWjUA93JBubm5TJ8+nejoaADee+89mjdvzsqVK+nUqRPPPfccd9xxB/fddx8A8fHxrFixgueee46rr77aY5zKlSu79+Hv71/Sj6XMZGdn85///IfFixe7C5wGDRrwww8/8Prrr9OzZ88y29fjjz/uno+KiuLhhx/m448/5t///re73dfXt8jP/mzjxo1j8ODBLF68uMziExEpazpjISJiId999x1Op5N169axfft2nn32WY/1mzdvJjIy0l1UALRo0YIqVaqwefNmd9uGDRuoXLmye+rXr1+JY/H19fUoVJo1a+axn82bN9O1a1ePbbp27eoRB0BmZiaVKlU6776GDBlC5cqVqV27NjfccEOhv9w/8sgjHscza9asQmO8+uqrVK5cmerVqxMdHc2XX35ZqM/27ds5fvw41157rcd477//Pjt27Dj/B1JCs2fPpmvXroSHh1O5cmUef/xxUlJSSjzOmjVrmDt3LpMnTy7T+EREypoKCxERC2nQoAFJSUm0aNGCV199lYkTJ7J+/foSj9O0aVPWrVvnnt56661LEG3x7N+/n4iIiPP2eeGFF1i3bh1ffvklubm5DBo0yGP9mDFjPI6nf//+hca4/fbbWbduHd999x3du3fn5ptvZt++fR59jh49CsBXX33lMd6mTZsueJ9FSSQnJ3P77bdz/fXXM3/+fNauXcu4cePIyckp8VgPPfQQDz/8MLVr1y6z+ERELgVdCiUiYiGtW7d238B7yy238NlnnzF06FBWrlyJv78/zZs3Z8+ePezZs8d91mLTpk0cPnyYFi1auMfx9/enUaNG7uW9e/eWOJZTp06xatUqOnXqBMDWrVs5fPgwzZs3B6B58+b8+OOPDBs2zL3Njz/+6BHHsWPH2Lx5M2PHjj3vvsLDw93xjho1ihtvvJHc3Fz8/PwAqFGjhsfxBAcHc/jwYY8xQkND3X0mTZrE1KlTC509adGiBQ6Hg5SUlDK97Olsy5cvp169eowbN87dtnv37hKP88UXX/Dbb7/x1VdflWV4IiKXhAoLERELe+WVV2jVqhWTJk1iypQpxMbG0rp1a26//XamTZvGqVOnuO++++jZsycdOnQo0337+flx//3389JLL+Hr68vIkSPp3Lmzu9AYM2YMgwYNol27dsTGxvLll1/y2Wefue8D2LJlC//+97+pUqXKBS/Fys3N5eTJkxw+fJiZM2fSpEkTd1FRXHl5eZw8eZLs7Gz+97//4efnR9OmTZk/f767T3BwMA8//DAPPvggTqeTbt26ceTIEX788UdCQkI8iqSznTp1ipMnT7rnDcNwL5+tcePGpKSk8PHHH9OxY0e++uor5s6dW6LjAXj22Wd5+eWXCQoKKvG2IiKXmy6FEhGxsGrVqvHmm2/yzDPP8NNPP2Gz2fj888+pWrUqPXr0IDY2lgYNGjB79uwy33dQUBCPPPIIt912G127dqVy5coe+4mLi+PFF1/kueeeo2XLlrz++uu888477ke7Tpw4kVOnTrF48WIqV6583n0NGjSIwMBAmjRpwoEDBy7qeKZPn05gYCA1a9bk7bffZtasWR73ouSbPHkyTzzxBAkJCTRv3py+ffvy1VdfUb9+/fOOP2bMGAIDAwkMDGTMmDGkpKS4l89+WlP//v158MEHGTlyJG3btmX58uU88cQTJT6mRo0anbfYERGxEpthGIbZQYiIiLW8++67jB49utDlRiIiIueiMxYiIiIiIlJqKixERERERKTUdCmUiIiIiIiUms5YiIiIiIhIqamwEBERERGRUlNhISIiIiIipabCQkRERERESk2FhYiIiIiIlJoKCxERERERKTUVFiIiIiIiUmoqLEREREREpNRUWIiIiIiISKn9PxFT7+KI444TAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if history:\n",
    "    history_df = pd.DataFrame(history)\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    axes[0].plot(history_df['epoch'], history_df['train_loss'], marker='o', color='tab:orange')\n",
    "    axes[0].set_title('Loss по эпохам')\n",
    "    axes[0].set_xlabel('Эпоха')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[1].plot(history_df['epoch'], history_df['val_f1'] * 100, marker='o', label='Val F1')\n",
    "    axes[1].plot(history_df['epoch'], history_df['train_f1'] * 100, marker='o', label='Train F1 (sample)')\n",
    "    axes[1].set_title('F1 по эпохам')\n",
    "    axes[1].set_xlabel('Эпоха')\n",
    "    axes[1].set_ylabel('F1, %')\n",
    "    axes[1].legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289adcf7",
   "metadata": {},
   "source": [
    "#### Итоговая оценка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0a557",
   "metadata": {},
   "source": [
    "Рассчитываем F1 на полном обучающем и валидационном множествах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48ac1f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-24 09:57:45,167 INFO: Финальные F1: train 87.23, val 86.80\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8722953314030896, 0.8680388554719392)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_train_f1 = evaluate_model_full(model, train_df)\n",
    "final_val_f1 = evaluate_model_full(model, val_df)\n",
    "logger.info('Финальные метрики: train F1 %.2f, val F1 %.2f', final_train_f1 * 100, final_val_f1 * 100)\n",
    "final_train_f1, final_val_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f60572",
   "metadata": {},
   "source": [
    "Фиксируем строки с минимальными значениями F1, чтобы понять типичные ошибки модели и уточнить параметры аугментации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846cbf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_details(df: pd.DataFrame, preds: Sequence[Sequence[int]]) -> pd.DataFrame:\n",
    "    '''\n",
    "    Собирает подробный отчет по precision/recall/F1 для каждой строки.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Датафрейм с колонками `no_space` и `true_positions`.\n",
    "    preds : Sequence[Sequence[int]]\n",
    "        Предсказанные позиции пробелов.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Датафрейм с метриками и восстановленными текстами.\n",
    "    '''\n",
    "    rows: list[dict[str, object]] = []\n",
    "    for no_space, gold, pred in zip(df['no_space'], df['true_positions'], preds):\n",
    "        gold_set = set(gold)\n",
    "        pred_set = set(pred)\n",
    "        tp = len(gold_set & pred_set)\n",
    "        fp = len(pred_set - gold_set)\n",
    "        fn = len(gold_set - pred_set)\n",
    "        precision = tp / (tp + fp) if (tp + fp) else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) else 0.0\n",
    "        rows.append({\n",
    "            'len': len(no_space),\n",
    "            'n_true': len(gold),\n",
    "            'n_pred': len(pred),\n",
    "            'tp': tp,\n",
    "            'fp': fp,\n",
    "            'fn': fn,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'no_space': no_space,\n",
    "            'true_positions': gold,\n",
    "            'pred_positions': pred,\n",
    "            'gold_text': apply_positions(no_space, gold),\n",
    "            'pred_text': apply_positions(no_space, pred),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "val_predictions = decode_positions_batch(model, val_df['no_space'].tolist())\n",
    "val_details = build_details(val_df, val_predictions)\n",
    "val_details.nsmallest(5, 'f1')[['no_space', 'gold_text', 'pred_text', 'f1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ad8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not val_details.empty:\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    val_details['f1'].plot(kind='hist', bins=40, color='tab:green', alpha=0.75)\n",
    "    plt.xlabel('F1 на валидации')\n",
    "    plt.title('Распределение F1 по примерам валидации')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 3))\n",
    "    grouped = val_details.groupby(pd.qcut(val_details['len'], q=8, duplicates='drop'))['f1'].mean()\n",
    "    grouped.plot(marker='o', color='tab:purple')\n",
    "    plt.ylabel('Средний F1')\n",
    "    plt.xlabel('Диапазон длины компактной строки')\n",
    "    plt.title('Зависимость F1 от длины строки')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    logger.warning('val_details пуст, графики F1 не построены')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b7b637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вес чекпоинта (ГБ): 0.153\n"
     ]
    }
   ],
   "source": [
    "print(f'Вес чекпоинта (ГБ): {CKPT_PATH.stat().st_size / 1e9:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a8fc9d",
   "metadata": {},
   "source": [
    "## Делаем submission"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006f4325",
   "metadata": {},
   "source": [
    "Следующий раздел можно запускать отдельно - он повторно импортирует библиотеки, создаёт все необходимые функции и никак не зависит от предыдущих ячеек. Достаточно указать путь к файлу с тестовыми примерами и к сохранённому чекпоинту."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fc94917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json as _json_infer\n",
    "import math as _math_infer\n",
    "import re as _re_infer\n",
    "import time as _time_infer\n",
    "import logging as _logging_infer\n",
    "import unicodedata as _unicodedata_infer\n",
    "from collections.abc import Sequence as _Sequence_infer\n",
    "from pathlib import Path as _Path_infer\n",
    "\n",
    "import numpy as _np_infer\n",
    "import pandas as _pd_infer\n",
    "import torch as _torch_infer\n",
    "import torch.nn as _nn_infer\n",
    "from tqdm.auto import tqdm as _tqdm_infer\n",
    "import csv as _csv_infer\n",
    "\n",
    "\n",
    "_INFER_SPACES = _re_infer.compile(r'\\s+')\n",
    "\n",
    "INFER_MAX_TOKENS = 512\n",
    "INFER_LEFT_CTX = 64\n",
    "INFER_RIGHT_CTX = 64\n",
    "INFER_DEVICE = 'cuda' if _torch_infer.cuda.is_available() else 'cpu'\n",
    "\n",
    "INFER_LOGGER = _logging_infer.getLogger('whitespace_infer')\n",
    "INFER_LOGGER.setLevel(_logging_infer.INFO)\n",
    "\n",
    "INFER_SUBMISSION_CSV = _Path_infer('submission.csv')            \n",
    "INFER_RESTORED_TXT = _Path_infer('restored_texts.txt')         \n",
    "INFER_BATCH_SIZE = 64\n",
    "\n",
    "INFER_INPUT_TXT = _Path_infer('dataset_1937770_3.txt')  \n",
    "INFER_CHECKPOINT = _Path_infer('experiments/eo_byte_finetune/checkpoint_epoch_3.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d028198e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _infer_apply_positions(no_space: str, positions: _Sequence_infer[int]) -> str:\n",
    "    '''\n",
    "    Восстанавливает пробелы в строке на основании списка индексов\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    no_space : str\n",
    "        Строка без пробелов\n",
    "    positions : Sequence[int]\n",
    "        Индексы, в которых нужно вставить пробелы\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Строка с восстановленными пробелами\n",
    "    '''\n",
    "    insert_positions = {int(p) for p in positions}\n",
    "    buf: list[str] = []\n",
    "    for i, ch in enumerate(no_space):\n",
    "        if i in insert_positions:\n",
    "            buf.append(' ')\n",
    "        buf.append(ch)\n",
    "    if len(no_space) in insert_positions:\n",
    "        buf.append(' ')\n",
    "    return _INFER_SPACES.sub(' ', ''.join(buf)).strip()\n",
    "\n",
    "\n",
    "def _infer_grapheme_spans(text: str) -> tuple[str, list[tuple[int, int]]]:\n",
    "    '''\n",
    "    Разбивает строку на графемы после нормализации\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Исходная строка\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[str, list[tuple[int, int]]]\n",
    "        Нормализованный текст и интервалы графем\n",
    "    '''\n",
    "    normalized = _unicodedata_infer.normalize('NFKC', text)\n",
    "    spans: list[tuple[int, int]] = []\n",
    "    start = 0\n",
    "    for idx in range(1, len(normalized)):\n",
    "        if _unicodedata_infer.combining(normalized[idx]):\n",
    "            continue\n",
    "        spans.append((start, idx))\n",
    "        start = idx\n",
    "    spans.append((start, len(normalized)))\n",
    "    return normalized, spans\n",
    "\n",
    "\n",
    "def _infer_token_byte_lengths(norm_text: str, spans: _Sequence_infer[tuple[int, int]]) -> _np_infer.ndarray:\n",
    "    '''\n",
    "    Возвращает длину каждой графемы в байтах UTF-8\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm_text : str\n",
    "        Нормализованный текст\n",
    "    spans : Sequence[tuple[int, int]]\n",
    "        Диапазоны графем\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Массив длин в байтах для каждой графемы\n",
    "    '''\n",
    "    return _np_infer.fromiter((len(norm_text[start:end].encode('utf-8', errors='ignore')) for start, end in spans), dtype=_np_infer.int32)\n",
    "\n",
    "\n",
    "def _infer_bytes_for_string(text: str) -> _np_infer.ndarray:\n",
    "    '''\n",
    "    Переводит строку в массив байтов UTF-8\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    text : str\n",
    "        Исходная строка\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Массив байтовых значений\n",
    "    '''\n",
    "    return _np_infer.frombuffer(text.encode('utf-8', errors='ignore'), dtype=_np_infer.uint8).copy()\n",
    "\n",
    "\n",
    "def _infer_make_token_windows(num_tokens: int, *, max_tokens: int, left_ctx: int, right_ctx: int) -> list[tuple[int, int, int, int]]:\n",
    "    '''\n",
    "    Делит последовательность графем на окна с контекстом\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_tokens : int\n",
    "        Количество графем\n",
    "    max_tokens : int\n",
    "        Максимальная длина окна\n",
    "    left_ctx : int\n",
    "        Размер левого контекста\n",
    "    right_ctx : int\n",
    "        Размер правого контекста\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[tuple[int, int, int, int]]\n",
    "        Список окон (start, end, core_start, core_end)\n",
    "    '''\n",
    "    if num_tokens <= max_tokens:\n",
    "        return [(0, num_tokens, 0, num_tokens)]\n",
    "    core = max_tokens - left_ctx - right_ctx\n",
    "    if core <= 0:\n",
    "        raise ValueError('Контекст не может быть больше окна')\n",
    "    windows: list[tuple[int, int, int, int]] = []\n",
    "    start = 0\n",
    "    while start < num_tokens:\n",
    "        core_start = start\n",
    "        core_end = min(start + core, num_tokens)\n",
    "        win_start = max(0, core_start - left_ctx)\n",
    "        win_end = min(num_tokens, core_end + right_ctx)\n",
    "        core_rel_start = core_start - win_start\n",
    "        core_rel_end = core_end - win_start\n",
    "        windows.append((win_start, win_end, core_rel_start, core_rel_end))\n",
    "        start = core_end\n",
    "    return windows\n",
    "\n",
    "\n",
    "def _infer_labels_to_positions(norm_text: str, spans: _Sequence_infer[tuple[int, int]], labels: _Sequence_infer[int]) -> list[int]:\n",
    "    '''\n",
    "    Преобразует метки классов в индексы вставки пробелов\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    norm_text : str\n",
    "        Нормализованный текст\n",
    "    spans : Sequence[tuple[int, int]]\n",
    "        Диапазоны графем\n",
    "    labels : Sequence[int]\n",
    "        Предсказанные метки\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[int]\n",
    "        Список индексов пробелов\n",
    "    '''\n",
    "    positions: list[int] = []\n",
    "    compact_idx = 0\n",
    "    for label, (start, end) in zip(labels, spans):\n",
    "        token = norm_text[start:end]\n",
    "        if token.strip() == '':\n",
    "            continue\n",
    "        if label == 1 and compact_idx > 0:\n",
    "            prev_char = norm_text[start - 1] if start > 0 else ''\n",
    "            if prev_char != ' ':\n",
    "                positions.append(compact_idx)\n",
    "        compact_idx += 1\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09b23240",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _InferSinusoidalPositionalEncoding(_nn_infer.Module):\n",
    "    '''\n",
    "    Синусоидальные позиционные кодировки для inference\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int\n",
    "        Размерность эмбеддингов\n",
    "    max_len : int, optional\n",
    "        Максимальная длина последовательности\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_model: int, max_len: int = 4096) -> None:\n",
    "        super().__init__()\n",
    "        position = _torch_infer.arange(0, max_len, dtype=_torch_infer.float32).unsqueeze(1)\n",
    "        div_term = _torch_infer.exp(_torch_infer.arange(0, d_model, 2, dtype=_torch_infer.float32) * (-_math_infer.log(10000.0) / d_model))\n",
    "        pe = _torch_infer.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = _torch_infer.sin(position * div_term)\n",
    "        pe[:, 1::2] = _torch_infer.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe.unsqueeze(0), persistent=False)\n",
    "\n",
    "    def forward(self, x: _torch_infer.Tensor) -> _torch_infer.Tensor:\n",
    "        '''\n",
    "        Добавляет позиционные кодировки к входному тензору\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : torch.Tensor\n",
    "            Тензор формы (batch, seq_len, d_model)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        torch.Tensor\n",
    "            Тензор с позиционными кодировками\n",
    "        '''\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]\n",
    "\n",
    "\n",
    "class _InferEOByteTransformer(_nn_infer.Module):\n",
    "    '''\n",
    "    Encoder-only Transformer для автономного inference\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    d_model : int, optional\n",
    "        Размерность эмбеддингов\n",
    "    nhead : int, optional\n",
    "        Количество голов внимания\n",
    "    num_layers : int, optional\n",
    "        Число слоев TransformerEncoder\n",
    "    dim_ff : int, optional\n",
    "        Размер скрытого слоя\n",
    "    dropout : float, optional\n",
    "        Доля дропаута\n",
    "    max_len : int, optional\n",
    "        Максимальная длина последовательности\n",
    "    '''\n",
    "\n",
    "    def __init__(self, d_model: int = 512, nhead: int = 8, num_layers: int = 12,\n",
    "                 dim_ff: int = 2048, dropout: float = 0.1, max_len: int = 4096) -> None:\n",
    "        super().__init__()\n",
    "        self.byte_embed = _nn_infer.Embedding(256, d_model)\n",
    "        encoder_layer = _nn_infer.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_ff,\n",
    "            dropout=dropout,\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.encoder = _nn_infer.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.positional = _InferSinusoidalPositionalEncoding(d_model, max_len=max_len)\n",
    "        self.head = _nn_infer.Linear(d_model, 3)\n",
    "\n",
    "    def forward_prepared(self, byte_values: list[_torch_infer.Tensor], token_lengths: list[_torch_infer.Tensor]) -> tuple[_torch_infer.Tensor, _torch_infer.Tensor]:\n",
    "        '''\n",
    "        Выполняет прямой проход по уже подготовленным байтовым представлениям\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        byte_values : list[torch.Tensor]\n",
    "            Батч байтовых представлений\n",
    "        token_lengths : list[torch.Tensor]\n",
    "            Длины графем для каждого образца\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        tuple[torch.Tensor, torch.Tensor]\n",
    "            Логиты и маска допустимых позиций\n",
    "        '''\n",
    "        device = self.byte_embed.weight.device\n",
    "        batch_size = len(byte_values)\n",
    "        embedding_dim = self.byte_embed.embedding_dim\n",
    "        max_tokens = max((int(lengths.numel()) for lengths in token_lengths), default=0)\n",
    "        if max_tokens == 0:\n",
    "            logits = _torch_infer.zeros((batch_size, 0, self.head.out_features), device=device)\n",
    "            attn_mask = _torch_infer.zeros((batch_size, 0), dtype=_torch_infer.bool, device=device)\n",
    "            return logits, attn_mask\n",
    "        padded = _torch_infer.zeros((batch_size, max_tokens, embedding_dim), device=device)\n",
    "        attn_mask = _torch_infer.zeros((batch_size, max_tokens), dtype=_torch_infer.bool, device=device)\n",
    "        zero_vec = _torch_infer.zeros(embedding_dim, device=device)\n",
    "        for idx, (byte_tensor, len_tensor) in enumerate(zip(byte_values, token_lengths)):\n",
    "            lengths = len_tensor.to(device=device, dtype=_torch_infer.long, non_blocking=True)\n",
    "            if lengths.numel() == 0:\n",
    "                continue\n",
    "            byte_tensor = byte_tensor.to(device=device, dtype=_torch_infer.long, non_blocking=True)\n",
    "            embedded = self.byte_embed(byte_tensor)\n",
    "            pointer = 0\n",
    "            token_vectors: list[_torch_infer.Tensor] = []\n",
    "            for length in lengths.tolist():\n",
    "                if length <= 0:\n",
    "                    token_vectors.append(zero_vec)\n",
    "                    continue\n",
    "                span = embedded[pointer:pointer + length]\n",
    "                if span.numel() == 0:\n",
    "                    token_vectors.append(zero_vec)\n",
    "                else:\n",
    "                    token_vectors.append(span.mean(dim=0))\n",
    "                pointer += length\n",
    "            if not token_vectors:\n",
    "                token_vectors.append(zero_vec)\n",
    "            stacked = _torch_infer.stack(token_vectors, dim=0)\n",
    "            seq_len = stacked.size(0)\n",
    "            padded[idx, :seq_len] = stacked\n",
    "            attn_mask[idx, :seq_len] = True\n",
    "        encoded = self.positional(padded)\n",
    "        encoded = self.encoder(encoded, src_key_padding_mask=~attn_mask)\n",
    "        logits = self.head(encoded)\n",
    "        return logits, attn_mask\n",
    "\n",
    "    def decode_positions(self, text: str, *, max_tokens: int = INFER_MAX_TOKENS,\n",
    "                         left_ctx: int = INFER_LEFT_CTX, right_ctx: int = INFER_RIGHT_CTX) -> list[int]:\n",
    "        '''\n",
    "        Декодирует индексы пробелов для одной строки\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text : str\n",
    "            Строка без пробелов\n",
    "        max_tokens : int, optional\n",
    "            Максимальная длина окна\n",
    "        left_ctx : int, optional\n",
    "            Размер левого контекста\n",
    "        right_ctx : int, optional\n",
    "            Размер правого контекста\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        list[int]\n",
    "            Предсказанные индексы пробелов\n",
    "        '''\n",
    "        norm_text, spans = _infer_grapheme_spans(text)\n",
    "        if not spans:\n",
    "            return []\n",
    "        labels: list[int] = []\n",
    "        token_lengths = _infer_token_byte_lengths(norm_text, spans)\n",
    "        byte_buffer = _infer_bytes_for_string(norm_text)\n",
    "        offsets = _np_infer.concatenate((_np_infer.array([0], dtype=_np_infer.int64), _np_infer.cumsum(token_lengths, dtype=_np_infer.int64)))\n",
    "        for win_start, win_end, core_rel_start, core_rel_end in _infer_make_token_windows(len(spans), max_tokens=max_tokens, left_ctx=left_ctx, right_ctx=right_ctx):\n",
    "            byte_start = int(offsets[win_start])\n",
    "            byte_end = int(offsets[win_end])\n",
    "            chunk_bytes = _torch_infer.from_numpy(byte_buffer[byte_start:byte_end].astype(_np_infer.int64, copy=True))\n",
    "            chunk_lengths = _torch_infer.from_numpy(token_lengths[win_start:win_end].astype(_np_infer.int64, copy=True))\n",
    "            logits, attn = self.forward_prepared([chunk_bytes.to(self.byte_embed.weight.device)], [chunk_lengths.to(self.byte_embed.weight.device)])\n",
    "            preds = logits[0].argmax(dim=-1)\n",
    "            valid = attn[0]\n",
    "            labels.extend(preds[valid].tolist()[core_rel_start:core_rel_end])\n",
    "        labels = labels[:len(spans)]\n",
    "        return _infer_labels_to_positions(norm_text, spans, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd89daf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_decode_positions_batch(model: _InferEOByteTransformer, texts: list[str], *,\n",
    "                                 max_tokens: int = INFER_MAX_TOKENS,\n",
    "                                 left_ctx: int = INFER_LEFT_CTX,\n",
    "                                 right_ctx: int = INFER_RIGHT_CTX,\n",
    "                                 batch_size: int = 64) -> list[list[int]]:\n",
    "    '''\n",
    "    Выполняет пакетное декодирование индексов пробелов для списка строк\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : _InferEOByteTransformer\n",
    "        Модель для inference\n",
    "    texts : list[str]\n",
    "        Список строк без пробелов\n",
    "    max_tokens : int, optional\n",
    "        Максимальная длина окна\n",
    "    left_ctx : int, optional\n",
    "        Размер левого контекста\n",
    "    right_ctx : int, optional\n",
    "        Размер правого контекста\n",
    "    batch_size : int, optional\n",
    "        Размер пакета при декодировании\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[list[int]]\n",
    "        Предсказанные индексы пробелов для каждой строки\n",
    "    '''\n",
    "    predictions: list[list[int]] = []\n",
    "    for start in range(0, len(texts), batch_size):\n",
    "        batch = texts[start:start + batch_size]\n",
    "        batch_preds = [model.decode_positions(text, max_tokens=max_tokens, left_ctx=left_ctx, right_ctx=right_ctx) for text in batch]\n",
    "        predictions.extend(batch_preds)\n",
    "    return predictions\n",
    "\n",
    "\n",
    "def _infer_load_model(path: _Path_infer) -> _InferEOByteTransformer:\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f'Нет чекпоинта: {path}')\n",
    "    payload = _torch_infer.load(path, map_location='cpu')\n",
    "    cfg = payload.get('cfg', {})\n",
    "\n",
    "    model = _InferEOByteTransformer(\n",
    "        d_model=cfg.get('d_model', 512),\n",
    "        nhead=cfg.get('nhead', 8),\n",
    "        num_layers=cfg.get('num_layers', cfg.get('layers', 12)),\n",
    "        dim_ff=cfg.get('dim_ff', 2048),\n",
    "        dropout=cfg.get('dropout', 0.1),\n",
    "        max_len=4096,\n",
    "    ).to(INFER_DEVICE)\n",
    "\n",
    "    sd = payload.get('state_dict', payload)\n",
    "    if any(k.startswith('_orig_mod.') for k in sd.keys()):\n",
    "        sd = {k.replace('_orig_mod.', '', 1): v for k, v in sd.items()}\n",
    "\n",
    "    if 'head.weight' in sd:\n",
    "        num_classes = sd['head.weight'].shape[0]\n",
    "        if model.head.out_features != num_classes:\n",
    "            model.head = _nn_infer.Linear(model.head.in_features, num_classes).to(INFER_DEVICE)\n",
    "\n",
    "    missing, unexpected = model.load_state_dict(sd, strict=False)\n",
    "    if missing:\n",
    "        INFER_LOGGER.warning('Отсутствуют ключи: %s', missing)\n",
    "    if unexpected:\n",
    "        INFER_LOGGER.warning('Лишние ключи: %s', unexpected)\n",
    "\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def _infer_read_input(path: _Path_infer) -> _pd_infer.DataFrame:\n",
    "    '''\n",
    "    Читает входной txt с форматом \"id,<текст_без_пробелов>\".\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : pathlib.Path\n",
    "        Путь к входному файлу.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Таблица с колонками: [\"id\", \"text_no_spaces\"].\n",
    "    '''\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f'Нет входного файла {path}')\n",
    "    rows = []\n",
    "    with path.open('r', encoding='utf-8') as fin:\n",
    "        for ln, line in enumerate(fin, 1):\n",
    "            line = line.rstrip('\\n\\r')\n",
    "            if not line:\n",
    "                continue\n",
    "            cpos = line.find(',')\n",
    "            if cpos == -1:\n",
    "                continue\n",
    "            id_part = line[:cpos].strip()\n",
    "            text_part = line[cpos + 1:].strip()\n",
    "            # пропускаем возможный заголовок\n",
    "            if ln == 1 and id_part.lower() in {'id', '\"id\"'}:\n",
    "                continue\n",
    "            if not id_part or not text_part:\n",
    "                continue\n",
    "            rows.append({\n",
    "                'id': id_part,\n",
    "                'text_raw': text_part,                \n",
    "                'text_no_spaces': _INFER_SPACES.sub('', text_part)  \n",
    "            })\n",
    "    return _pd_infer.DataFrame(rows)\n",
    "\n",
    "\n",
    "def _infer_batch_decode(model: _InferEOByteTransformer, texts: list[str], batch_size: int) -> list[list[int]]:\n",
    "    '''\n",
    "    Пакетно декодирует позиции пробелов для списка строк.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : _InferEOByteTransformer\n",
    "        Модель инференса.\n",
    "    texts : list[str]\n",
    "        Строки без пробелов.\n",
    "    batch_size : int\n",
    "        Размер батча.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[list[int]]\n",
    "        Список массивов позиций пробелов для каждой строки.\n",
    "    '''\n",
    "    out: list[list[int]] = []\n",
    "    for start in _tqdm_infer(range(0, len(texts), batch_size), desc='inference', unit='batch'):\n",
    "        batch = texts[start:start + batch_size]\n",
    "        out.extend([model.decode_positions(t) for t in batch])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bfc868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n",
      "inference: 100%|██████████| 16/16 [00:06<00:00,  2.30batch/s]\n"
     ]
    }
   ],
   "source": [
    "model = _infer_load_model(INFER_CHECKPOINT)\n",
    "df = _infer_read_input(INFER_INPUT_TXT)\n",
    "texts = df['text_no_spaces'].astype(str).tolist()\n",
    "\n",
    "\n",
    "if INFER_DEVICE == 'cuda':\n",
    "    _torch_infer.cuda.synchronize()\n",
    "t0 = _time_infer.perf_counter()\n",
    "\n",
    "preds = _infer_batch_decode(model, texts, INFER_BATCH_SIZE)\n",
    "\n",
    "if INFER_DEVICE == 'cuda':\n",
    "    _torch_infer.cuda.synchronize()\n",
    "dt = _time_infer.perf_counter() - t0\n",
    "\n",
    "INFER_LOGGER.info('Инференс: %.2f c (%.2f строк/с)', dt, len(texts) / max(dt, 1e-6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c48904dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicted_positions'] = preds\n",
    "\n",
    "def _pos_to_str(pos):\n",
    "    if not pos:\n",
    "        return \"[]\"\n",
    "    vals = sorted({int(x) for x in pos})\n",
    "    return \"[\" + \", \".join(str(v) for v in vals) + \"]\"\n",
    "\n",
    "df_out = _pd_infer.DataFrame({\n",
    "    'id': df['id'].astype(str),\n",
    "    'text_no_spaces': df['text_raw'],  \n",
    "    'predicted_positions': [_pos_to_str(p) for p in df['predicted_positions']]\n",
    "})\n",
    "\n",
    "df_out.to_csv(INFER_SUBMISSION_CSV, index=False, encoding='utf-8', quoting=_csv_infer.QUOTE_MINIMAL)\n",
    "\n",
    "with INFER_RESTORED_TXT.open('w', encoding='utf-8') as fout:\n",
    "    for row, pos in zip(df.itertuples(index=False), preds):\n",
    "        restored = _infer_apply_positions(str(row.text_no_spaces), pos)\n",
    "        fout.write(f'{row.id},{restored}\\n')\n",
    "\n",
    "INFER_LOGGER.info('Сохранено: %s  (rows=%d)', INFER_SUBMISSION_CSV, len(df_out))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c60c4d",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6cc8163",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m IPYNB_TIME_END \u001b[38;5;241m=\u001b[39m \u001b[43mtime\u001b[49m\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      3\u001b[0m full_time \u001b[38;5;241m=\u001b[39m IPYNB_TIME_END \u001b[38;5;241m-\u001b[39m IPYNB_TIME_START\n\u001b[1;32m      4\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mВремя выполнения ноутбука: \u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m минут (\u001b[39m\u001b[38;5;132;01m%.2f\u001b[39;00m\u001b[38;5;124m часов)\u001b[39m\u001b[38;5;124m'\u001b[39m, full_time \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m, full_time \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3600\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "IPYNB_TIME_END = time.time()\n",
    "\n",
    "full_time = IPYNB_TIME_END - IPYNB_TIME_START\n",
    "logger.info('Время выполнения ноутбука: %.2f минут (%.2f часов)', full_time / 60, full_time / 3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409ed0a3",
   "metadata": {},
   "source": [
    "Новый подход, который мы адаптировали из статьи, сделал наше решение быстрым и лёгким, что идеально подходит для продакшен-сценариев с ограниченными ресурсами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae078d1b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
